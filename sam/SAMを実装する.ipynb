{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAMを実装する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy.special import expit\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "random.seed(1234)\n",
    "np.set_printoptions(precision=2, floatmode='fixed', suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(n_data=2000):\n",
    "\n",
    "    x = np.random.uniform(low=-1, high=1, size=n_data)  # -1から1の一様乱数\n",
    "\n",
    "    e_z = np.random.randn(n_data)  # ノイズの生成\n",
    "    z_prob = scipy.special.expit(-5.0 * x + 5 * e_z)\n",
    "    Z = np.array([])\n",
    "\n",
    "    for i in range(n_data):\n",
    "        Z_i = np.random.choice(2, size=1, p=[1-z_prob[i], z_prob[i]])[0]\n",
    "        Z = np.append(Z, Z_i)\n",
    "\n",
    "    t = np.zeros(n_data)\n",
    "    for i in range(n_data):\n",
    "        if x[i] < 0:\n",
    "            t[i] = 0.5\n",
    "        elif x[i] >= 0 and x[i] < 0.5:\n",
    "            t[i] = 0.7\n",
    "        elif x[i] >= 0.5:\n",
    "            t[i] = 1.0\n",
    "\n",
    "    e_y = np.random.randn(n_data)\n",
    "    Y = 2.0 + t*Z + 0.3*x + 0.1*e_y \n",
    "\n",
    "    Y2 = np.random.choice(\n",
    "        [1.0, 2.0, 3.0, 4.0, 5.0],\n",
    "        n_data, p=[0.1, 0.2, 0.3, 0.2, 0.2]\n",
    "    )\n",
    "\n",
    "    e_y3 = np.random.randn(n_data)\n",
    "    Y3 = 2 * x + e_y3\n",
    "\n",
    "    data = pd.DataFrame({\n",
    "        'x': x,\n",
    "        'Z': Z,\n",
    "        'Y': Y,\n",
    "        'Y2': Y2,\n",
    "        'Y3': Y3\n",
    "    })\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalMatrixNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_datal_col):\n",
    "        \n",
    "        super(CausalMatrixNN, self).__init__()\n",
    "\n",
    "        self.weights = torch.nn.Parameter(torch.ones(n_data_col, n_data_col))\n",
    "        self.mask = 1 - torch.eye(n_data_col, n_data_col)\n",
    "        \n",
    "    def forward(self):\n",
    "        return self.weights * self.mask\n",
    "    \n",
    "    def predict_proba(self):\n",
    "        return torch.sigmoid(self.weights) * self.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAMGenerator(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_data_col, hidden_layer_size_list):\n",
    "        \n",
    "        super(SAMGenerator, self).__init__()\n",
    "        \n",
    "        self.n_data_col = n_data_col\n",
    "        self.weight_input = nn.Parameter(torch.normal(0, std=0.1, size=(n_data_col + 1, n_data_col + 1)))\n",
    "        self.bias_input = nn.Parameter(torch.normal(0, std=0.1, size=(n_data_col, n_data_col + 1)))\n",
    "        \n",
    "        layers = []\n",
    "        hidden_layer_size_list = [n_data_col] + hidden_layer_size_list\n",
    "        for i in range(len(hidden_layer_size_list) - 1):\n",
    "            layer_input = hidden_layer_size_list[i]\n",
    "            layer_output = hidden_layer_size_list[i + 1]\n",
    "            layers.append(nn.Linear(layer_input, layer_output))\n",
    "            layers.append(nn.BatchNorm1d(layer_output))\n",
    "            layers.append(nn.LeakyReLU(.2))\n",
    "            \n",
    "        layers.append(nn.Linear(hidden_layer_size_list[-1], n_data_col))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "        \n",
    "    def forward(self, X, noise, adj_matrix):\n",
    "        \n",
    "        h = torch.cat([\n",
    "            X.unsqueeze(1).expand([X.shape[0], self.n_data_col, self.n_data_col]),\n",
    "            noise.unsqueeze(2)\n",
    "        ], 2)\n",
    "        h = h * adj_matrix.t().unsqueeze(0)\n",
    "\n",
    "        h = h.matmul(self.weight_input) + self.bias_input\n",
    "        h = h.sum(axis=2)\n",
    "        \n",
    "        return self.layers(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAMDiscriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_data_col, hidden_layer_size_list):\n",
    "        \n",
    "        super(SAMDiscriminator, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        hidden_layer_size_list = [n_data_col] + hidden_layer_size_list\n",
    "        for i in range(len(hidden_layer_size_list) - 1):\n",
    "            layer_input = hidden_layer_size_list[i]\n",
    "            layer_output = hidden_layer_size_list[i + 1]\n",
    "            layers.append(torch.nn.Linear(layer_input, layer_output))\n",
    "            layers.append(torch.nn.BatchNorm1d(layer_output))\n",
    "            layers.append(torch.nn.LeakyReLU(.2))\n",
    "            \n",
    "        layers.append(nn.Linear(hidden_layer_size_list[-1], 1))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.layers(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notears_constr(adj_m, max_pow=None):\n",
    "    \n",
    "    m_exp = [adj_m]\n",
    "    if max_pow is None:\n",
    "        max_pow = adj_m.shape[1]\n",
    "    while (m_exp[-1].sum() > 0 and len(m_exp) < max_pow):\n",
    "        m_exp.append(m_exp[-1] @ adj_m / len(m_exp))\n",
    "        \n",
    "    return sum([i.diag().sum() for idx, i in enumerate(m_exp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = make_data(n_data=5000)\n",
    "learning_data = data.copy()\n",
    "learning_data.loc[:, :] = scale(learning_data.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = learning_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data_col = data.shape[1]\n",
    "data = torch.from_numpy(data.values.astype('float32') )\n",
    "batch_size = len(data)\n",
    "\n",
    "data_iterator = DataLoader(\n",
    "    data, batch_size=batch_size, shuffle=True, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_size_list_gen = [500, 500, 500]\n",
    "hidden_layer_size_list_dis = [500, 500, 100]\n",
    "epoch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0.00 1.00 1.00 1.00 1.00]\n",
      " [1.00 0.00 1.00 1.00 1.00]\n",
      " [1.00 1.00 0.00 1.00 1.00]\n",
      " [1.00 1.00 1.00 0.00 1.00]\n",
      " [1.00 1.00 1.00 1.00 0.00]]\n",
      "\n",
      "[10/ 1000] Loss Dis: 1.42, Loss Gen: 0.52, 11[s]\n",
      "[20/ 1000] Loss Dis: 1.41, Loss Gen: 0.54, 12[s]\n",
      "[30/ 1000] Loss Dis: 1.39, Loss Gen: 0.58, 11[s]\n",
      "[40/ 1000] Loss Dis: 1.39, Loss Gen: 0.58, 11[s]\n",
      "[50/ 1000] Loss Dis: 1.39, Loss Gen: 0.59, 11[s]\n",
      "[60/ 1000] Loss Dis: 1.38, Loss Gen: 0.62, 11[s]\n",
      "[70/ 1000] Loss Dis: 1.36, Loss Gen: 0.61, 11[s]\n",
      "[80/ 1000] Loss Dis: 1.35, Loss Gen: 0.62, 11[s]\n",
      "[90/ 1000] Loss Dis: 1.33, Loss Gen: 0.63, 11[s]\n",
      "[100/ 1000] Loss Dis: 1.33, Loss Gen: 0.64, 11[s]\n",
      "\n",
      "[[0.00 0.90 0.90 0.90 0.90]\n",
      " [0.90 0.00 0.90 0.90 0.90]\n",
      " [0.90 0.90 0.00 0.90 0.90]\n",
      " [0.90 0.90 0.90 0.00 0.90]\n",
      " [0.90 0.90 0.90 0.90 0.00]]\n",
      "\n",
      "[110/ 1000] Loss Dis: 1.31, Loss Gen: 0.64, 11[s]\n",
      "[120/ 1000] Loss Dis: 1.27, Loss Gen: 0.65, 11[s]\n",
      "[130/ 1000] Loss Dis: 1.30, Loss Gen: 0.66, 11[s]\n",
      "[140/ 1000] Loss Dis: 1.28, Loss Gen: 0.67, 12[s]\n",
      "[150/ 1000] Loss Dis: 1.26, Loss Gen: 0.66, 12[s]\n",
      "[160/ 1000] Loss Dis: 1.31, Loss Gen: 0.65, 11[s]\n",
      "[170/ 1000] Loss Dis: 1.29, Loss Gen: 0.67, 12[s]\n",
      "[180/ 1000] Loss Dis: 1.28, Loss Gen: 0.67, 11[s]\n",
      "[190/ 1000] Loss Dis: 1.29, Loss Gen: 0.65, 11[s]\n",
      "[200/ 1000] Loss Dis: 1.31, Loss Gen: 0.66, 11[s]\n",
      "\n",
      "[[0.00 0.80 0.80 0.80 0.80]\n",
      " [0.80 0.00 0.80 0.80 0.80]\n",
      " [0.80 0.80 0.00 0.80 0.80]\n",
      " [0.80 0.80 0.80 0.00 0.80]\n",
      " [0.80 0.80 0.80 0.80 0.00]]\n",
      "\n",
      "[210/ 1000] Loss Dis: 1.28, Loss Gen: 0.66, 11[s]\n",
      "[220/ 1000] Loss Dis: 1.28, Loss Gen: 0.67, 11[s]\n",
      "[230/ 1000] Loss Dis: 1.23, Loss Gen: 0.67, 11[s]\n",
      "[240/ 1000] Loss Dis: 1.21, Loss Gen: 0.67, 11[s]\n",
      "[250/ 1000] Loss Dis: 1.18, Loss Gen: 0.67, 11[s]\n",
      "[260/ 1000] Loss Dis: 1.16, Loss Gen: 0.67, 11[s]\n",
      "[270/ 1000] Loss Dis: 1.14, Loss Gen: 0.67, 11[s]\n",
      "[280/ 1000] Loss Dis: 1.13, Loss Gen: 0.67, 11[s]\n",
      "[290/ 1000] Loss Dis: 1.12, Loss Gen: 0.68, 11[s]\n",
      "[300/ 1000] Loss Dis: 1.10, Loss Gen: 0.68, 11[s]\n",
      "\n",
      "[[0.00 0.70 0.70 0.70 0.70]\n",
      " [0.70 0.00 0.70 0.70 0.70]\n",
      " [0.70 0.70 0.00 0.70 0.70]\n",
      " [0.70 0.70 0.70 0.00 0.70]\n",
      " [0.70 0.70 0.70 0.70 0.00]]\n",
      "\n",
      "[310/ 1000] Loss Dis: 1.09, Loss Gen: 0.68, 11[s]\n",
      "[320/ 1000] Loss Dis: 1.09, Loss Gen: 0.68, 11[s]\n",
      "[330/ 1000] Loss Dis: 1.13, Loss Gen: 0.67, 11[s]\n",
      "[340/ 1000] Loss Dis: 1.13, Loss Gen: 0.67, 11[s]\n",
      "[350/ 1000] Loss Dis: 1.10, Loss Gen: 0.68, 11[s]\n",
      "[360/ 1000] Loss Dis: 1.10, Loss Gen: 0.68, 11[s]\n",
      "[370/ 1000] Loss Dis: 1.10, Loss Gen: 0.68, 11[s]\n",
      "[380/ 1000] Loss Dis: 1.09, Loss Gen: 0.69, 11[s]\n",
      "[390/ 1000] Loss Dis: 1.08, Loss Gen: 0.69, 11[s]\n",
      "[400/ 1000] Loss Dis: 1.08, Loss Gen: 0.69, 11[s]\n",
      "\n",
      "[[0.00 0.60 0.60 0.60 0.60]\n",
      " [0.60 0.00 0.60 0.60 0.60]\n",
      " [0.60 0.60 0.00 0.60 0.60]\n",
      " [0.60 0.60 0.60 0.00 0.60]\n",
      " [0.60 0.60 0.60 0.60 0.00]]\n",
      "\n",
      "[410/ 1000] Loss Dis: 1.08, Loss Gen: 0.69, 11[s]\n",
      "[420/ 1000] Loss Dis: 1.07, Loss Gen: 0.69, 11[s]\n",
      "[430/ 1000] Loss Dis: 1.07, Loss Gen: 0.69, 11[s]\n",
      "[440/ 1000] Loss Dis: 1.07, Loss Gen: 0.69, 11[s]\n",
      "[450/ 1000] Loss Dis: 1.06, Loss Gen: 0.69, 11[s]\n",
      "[460/ 1000] Loss Dis: 1.07, Loss Gen: 0.69, 11[s]\n",
      "[470/ 1000] Loss Dis: 1.09, Loss Gen: 0.68, 11[s]\n",
      "[480/ 1000] Loss Dis: 1.09, Loss Gen: 0.68, 11[s]\n",
      "[490/ 1000] Loss Dis: 1.09, Loss Gen: 0.68, 11[s]\n",
      "[500/ 1000] Loss Dis: 1.09, Loss Gen: 0.68, 11[s]\n",
      "\n",
      "[[0.00 0.50 0.50 0.50 0.50]\n",
      " [0.50 0.00 0.50 0.50 0.50]\n",
      " [0.50 0.50 0.00 0.50 0.50]\n",
      " [0.50 0.50 0.50 0.00 0.50]\n",
      " [0.50 0.50 0.50 0.50 0.00]]\n",
      "\n",
      "[510/ 1000] Loss Dis: 1.29, Loss Gen: 0.67, 11[s]\n",
      "[520/ 1000] Loss Dis: 1.28, Loss Gen: 0.66, 11[s]\n",
      "[530/ 1000] Loss Dis: 1.36, Loss Gen: 0.66, 11[s]\n",
      "[540/ 1000] Loss Dis: 1.26, Loss Gen: 0.67, 11[s]\n",
      "[550/ 1000] Loss Dis: 1.28, Loss Gen: 0.68, 11[s]\n",
      "[560/ 1000] Loss Dis: 1.37, Loss Gen: 0.65, 11[s]\n",
      "[570/ 1000] Loss Dis: 1.31, Loss Gen: 0.69, 11[s]\n",
      "[580/ 1000] Loss Dis: 1.30, Loss Gen: 0.67, 12[s]\n",
      "[590/ 1000] Loss Dis: 1.26, Loss Gen: 0.67, 13[s]\n",
      "[600/ 1000] Loss Dis: 1.20, Loss Gen: 0.69, 12[s]\n",
      "\n",
      "[[0.00 0.39 0.39 0.39 0.39]\n",
      " [0.39 0.00 0.39 0.39 0.39]\n",
      " [0.39 0.39 0.00 0.39 0.39]\n",
      " [0.39 0.39 0.39 0.00 0.39]\n",
      " [0.39 0.39 0.39 0.39 0.00]]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-f4bf0b84e622>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mdata_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_batched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madj_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0moutput_gen_detach\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0moutput_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         loss_dis = criterion(output_gen_detach,  torch.zeros(output_gen_detach.shape)) + criterion(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-218b76a2fddb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "structural_gates = CausalMatrixNN(n_data_col)\n",
    "sam = SAMGenerator(n_data_col=n_data_col, hidden_layer_size_list=hidden_layer_size_list_gen)\n",
    "dis = SAMDiscriminator(n_data_col=n_data_col, hidden_layer_size_list=hidden_layer_size_list_dis)\n",
    "\n",
    "noise = torch.randn(batch_size, n_data_col)\n",
    "\n",
    "optimizer_gen = optim.Adam(sam.parameters())\n",
    "optimizer_dis = optim.Adam(dis.parameters())\n",
    "optimizer_gate = optim.Adam(structural_gates.parameters())\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "start_time = time.time()\n",
    "for loop in range(epoch):\n",
    "    for data_batched in data_iterator:\n",
    "        \n",
    "        optimizer_gen.zero_grad()\n",
    "        optimizer_gate.zero_grad()\n",
    "        optimizer_dis.zero_grad()\n",
    "\n",
    "        adj_matrix = torch.cat([structural_gates(), torch.ones(1, n_data_col)], 0)\n",
    "        noise.normal_()\n",
    "\n",
    "        data_gen = sam(X=data_batched, noise=noise, adj_matrix=adj_matrix)\n",
    "        output_gen_detach = dis(data_gen.detach())\n",
    "        output_true = dis(data_batched)\n",
    "\n",
    "        loss_dis = criterion(output_gen_detach,  torch.zeros(output_gen_detach.shape)) + criterion(\n",
    "            output_true, torch.ones(output_true.shape)\n",
    "        )\n",
    "        \n",
    "        loss_dis.backward()\n",
    "        optimizer_dis.step()\n",
    "        \n",
    "        output_gen = dis(data_gen)\n",
    "        gates = structural_gates()\n",
    "        loss_gen = criterion(output_gen, torch.ones(output_gen.shape))\n",
    "        loss = loss_gen + gates.sum()\n",
    "        if loop > epoch / 2:\n",
    "            gates = structural_gates.predict_proba()\n",
    "            loss = loss + notears_constr(gates * gates) / n_data_col\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer_gen.step()\n",
    "        optimizer_gate.step()\n",
    "        \n",
    "        if (loop + 1) % 10 == 0:\n",
    "            \n",
    "            print('[{}/ {}] Loss Dis: {:.2f}, Loss Gen: {:.2f}, {:.0f}[s]'.format(\n",
    "                loop + 1, epoch, loss_dis, loss_gen, time.time() - start_time\n",
    "            ))\n",
    "            start_time = time.time()\n",
    "        \n",
    "        if loop % 100 == 0:\n",
    "            print('')\n",
    "            print(structural_gates().detach().numpy())\n",
    "            print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notears_constr(gates * gates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(output_gen_detach,  torch.zeros(output_gen_detach.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4858, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(\n",
    "            output_true, torch.ones(output_true.shape)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4530,  0.0726,  0.4511,  0.1313, -0.1351, -0.1234],\n",
       "        [ 0.5551, -0.1602, -0.0725,  0.1496, -0.2958,  0.1390],\n",
       "        [ 0.5793, -0.1725, -0.0989,  0.1751, -0.3039,  0.1149],\n",
       "        ...,\n",
       "        [ 0.4760, -0.1629, -0.0676,  0.1756, -0.2365,  0.1156],\n",
       "        [ 0.5232, -0.1560, -0.0699,  0.1628, -0.2727,  0.1226],\n",
       "        [ 0.6975, -0.2295, -0.1397,  0.1622, -0.3318,  0.1525]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_matrix = torch.cat([structural_gates(), torch.ones(1, n_data_col)], 0)\n",
    "noise.normal_()\n",
    "\n",
    "sam(X=data, noise=noise, adj_matrix=adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0288,  0.9588, -0.0717, -0.9565, -0.7468, -0.8526],\n",
       "        [ 0.4281,  0.9588,  1.5529, -0.1527,  0.3245,  0.2860],\n",
       "        [-0.1957, -1.0429, -0.3203, -0.1527,  0.2314,  0.5084],\n",
       "        ...,\n",
       "        [ 1.2523, -1.0429, -0.2571, -0.1527, -0.0278,  0.3842],\n",
       "        [ 1.5519, -1.0429, -0.1780,  0.6510,  0.1190,  0.2537],\n",
       "        [ 1.2993, -1.0429, -0.4257,  0.6510,  0.6279,  0.8868]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
