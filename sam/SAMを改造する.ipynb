{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAMを実装する 〜Original〜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy.special import expit\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from cdt.utils.torch import ChannelBatchNorm1d, MatrixSampler, Linear3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "random.seed(1234)\n",
    "np.set_printoptions(precision=2, floatmode='fixed', suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関数定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(n_data=2000):\n",
    "\n",
    "    x = np.random.uniform(low=-1, high=1, size=n_data)  # -1から1の一様乱数\n",
    "\n",
    "    e_z = np.random.randn(n_data)  # ノイズの生成\n",
    "    z_prob = scipy.special.expit(-5.0 * x + 5 * e_z)\n",
    "    Z = np.array([])\n",
    "\n",
    "    for i in range(n_data):\n",
    "        Z_i = np.random.choice(2, size=1, p=[1-z_prob[i], z_prob[i]])[0]\n",
    "        Z = np.append(Z, Z_i)\n",
    "\n",
    "    t = np.zeros(n_data)\n",
    "    for i in range(n_data):\n",
    "        if x[i] < 0:\n",
    "            t[i] = 0.5\n",
    "        elif x[i] >= 0 and x[i] < 0.5:\n",
    "            t[i] = 0.7\n",
    "        elif x[i] >= 0.5:\n",
    "            t[i] = 1.0\n",
    "\n",
    "    e_y = np.random.randn(n_data)\n",
    "    Y = 2.0 + t*Z + 0.3*x + 0.1*e_y \n",
    "\n",
    "    Y2 = np.random.choice(\n",
    "        [1.0, 2.0, 3.0, 4.0, 5.0],\n",
    "        n_data, p=[0.1, 0.2, 0.3, 0.2, 0.2]\n",
    "    )\n",
    "\n",
    "    e_y3 = np.random.randn(n_data)\n",
    "    Y3 = 3 * x + e_y3\n",
    "\n",
    "    data = pd.DataFrame({\n",
    "        'x': x,\n",
    "        'Z': Z,\n",
    "        'Y': Y,\n",
    "        'Y2': Y2,\n",
    "        'Y3': Y3\n",
    "    })\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAMDiscriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_data_col, n_hidden_layer, n_hidden_layers):\n",
    "        \n",
    "        super(SAMDiscriminator, self).__init__()\n",
    "        \n",
    "        self.n_data_col = n_data_col\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(nn.Linear(n_data_col, n_hidden_layer))\n",
    "        layers.append(nn.BatchNorm1d(n_hidden_layer))\n",
    "        layers.append(nn.LeakyReLU(.2))\n",
    "        \n",
    "        for i in range(n_hidden_layers - 1):\n",
    "            layers.append(nn.Linear(n_hidden_layer, n_hidden_layer))\n",
    "            layers.append(nn.BatchNorm1d(n_hidden_layer))\n",
    "            layers.append(nn.LeakyReLU(.2))\n",
    "            \n",
    "        layers.append(nn.Linear(n_hidden_layer, 1))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "        self.register_buffer(\n",
    "            'mask', torch.eye(n_data_col, n_data_col).unsqueeze(0)\n",
    "        )\n",
    "        \n",
    "    def forward(self, input, obs_data=None):\n",
    "        \n",
    "        if obs_data is not None:\n",
    "            return [\n",
    "                self.layers(i) for i in torch.unbind(\n",
    "                    obs_data.unsqueeze(1) * (1 - self.mask) + input.unsqueeze(1) * self.mask,\n",
    "                    1\n",
    "                )\n",
    "            ]\n",
    "        else:\n",
    "            return self.layers(input)\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, 'reset_parameters'):\n",
    "                layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAMGenerator(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_data_col, n_hidden_layer):\n",
    "        \n",
    "        super(SAMGenerator, self).__init__()\n",
    "        \n",
    "        skeleton = 1 - torch.eye(n_data_col + 1, n_data_col)\n",
    "        \n",
    "        self.register_buffer('skeleton', skeleton)\n",
    "        \n",
    "        self.input_layer = Linear3D((n_data_col, n_data_col + 1, n_hidden_layer))\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(ChannelBatchNorm1d(n_data_col, n_hidden_layer))\n",
    "        layers.append(nn.Tanh())\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "        self.output_layer = Linear3D((n_data_col, n_hidden_layer, 1))\n",
    "        \n",
    "    def forward(self, data, noise, adj_matrix, drawn_neurons=None):\n",
    "        \n",
    "        x = self.input_layer(data, noise, adj_matrix * self.skeleton)\n",
    "        \n",
    "        x = self.layers(x)\n",
    "        \n",
    "        output = self.output_layer(x, noise=None, adj_matrix=drawn_neurons)\n",
    "        \n",
    "        return output.squeeze(2)\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        \n",
    "        self.input_layer.reset_parameters()\n",
    "        self.output_layer.reset_parameters()\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, 'reset_parametres'):\n",
    "                layer.register_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notears_constr(adj_m, max_pow=None):\n",
    "    \n",
    "    m_exp = [adj_m]\n",
    "    if max_pow is None:\n",
    "        max_pow = adj_m.shape[1]\n",
    "    while (m_exp[-1].sum() > 0 and len(m_exp) < max_pow):\n",
    "        m_exp.append(m_exp[-1] @ adj_m / len(m_exp))\n",
    "        \n",
    "    return sum([i.diag().sum() for idx, i in enumerate(m_exp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sam_model(\n",
    "    data,\n",
    "    n_hidden_layer_gen=100, n_hidden_layer_dis=100,\n",
    "    n_hidden_layers_dis=2,\n",
    "    lr_gen=0.01*0.5, lr_dis=0.01*0.5*2,\n",
    "    dag_start_rate=0.5, dag_penalization_increase=0.001*10,\n",
    "    epochs_train=100, epochs_test=100,\n",
    "    lambda1=5.0*20, lambda2=0.005*20\n",
    "):\n",
    "\n",
    "    data_columns = data.columns.tolist() \n",
    "    n_data_col = len(data_columns)  \n",
    "    data = torch.from_numpy(data.values.astype('float32') )\n",
    "    batch_size = len(data)\n",
    "\n",
    "    data_iterator = DataLoader(\n",
    "        data, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "\n",
    "    sam = SAMGenerator(n_data_col, n_hidden_layer_gen)\n",
    "    sam.reset_parameters()\n",
    "    sampler_graph = MatrixSampler(n_data_col, mask=None, gumbel=False)\n",
    "    sampler_neuron = MatrixSampler((n_hidden_layer_gen, n_data_col), mask=False, gumbel=True)\n",
    "\n",
    "    sampler_graph.weights.data.fill_(2)\n",
    "\n",
    "    discriminator = SAMDiscriminator(\n",
    "        n_data_col=n_data_col, n_hidden_layer=n_hidden_layer_dis, n_hidden_layers=n_hidden_layers_dis\n",
    "    )\n",
    "    discriminator.reset_parameters()  \n",
    "\n",
    "    optimizer_gen = optim.Adam(sam.parameters(), lr=lr_gen)\n",
    "    optimizer_dis = optim.Adam(discriminator.parameters(), lr=lr_dis)\n",
    "    optimizer_graph = optim.Adam(sampler_graph.parameters(), lr=lr_gen)\n",
    "    optimizer_neuron = optim.Adam(sampler_neuron.parameters(), lr=lr_gen)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    _true = torch.ones(1)\n",
    "    _false = torch.zeros(1)\n",
    "\n",
    "    noise = torch.randn(batch_size, n_data_col)\n",
    "    noise_row = torch.ones(1, n_data_col)\n",
    "\n",
    "    output = torch.zeros(n_data_col, n_data_col)\n",
    "    output_loss = torch.zeros(1, 1)\n",
    "\n",
    "    pbar = tqdm(range(epochs_train + epochs_test))\n",
    "    for epoch in pbar:\n",
    "        for loop_num, data_batched in enumerate(data_iterator):\n",
    "\n",
    "            optimizer_gen.zero_grad()\n",
    "            optimizer_graph.zero_grad()\n",
    "            optimizer_neuron.zero_grad()\n",
    "            optimizer_dis.zero_grad()\n",
    "\n",
    "            drawn_graph = sampler_graph()\n",
    "            drawn_neurons = sampler_neuron()\n",
    "\n",
    "            noise.normal_()\n",
    "            generated_variables = sam(\n",
    "                data=data_batched, \n",
    "                noise=noise,\n",
    "                adj_matrix=torch.cat(\n",
    "                    [drawn_graph, noise_row], 0\n",
    "                ), \n",
    "                drawn_neurons=drawn_neurons\n",
    "            )\n",
    "\n",
    "            dis_vars_d = discriminator(generated_variables.detach(), data_batched)\n",
    "            dis_vars_g = discriminator(generated_variables, data_batched)\n",
    "            true_vars_dis = discriminator(data_batched) \n",
    "\n",
    "            loss_dis = sum(\n",
    "                [criterion(gen, _false.expand_as(gen)) for gen in dis_vars_d]\n",
    "            ) / n_data_col + criterion(\n",
    "                true_vars_dis, _true.expand_as(true_vars_dis)\n",
    "            )\n",
    "\n",
    "            loss_gen = sum([criterion(gen, _true.expand_as(gen)) for gen in dis_vars_g])\n",
    "\n",
    "            if epoch < epochs_train:\n",
    "                loss_dis.backward()\n",
    "                optimizer_dis.step()\n",
    "\n",
    "            loss_struc = lambda1 / batch_size * drawn_graph.sum()     \n",
    "            loss_func = lambda2 / batch_size * drawn_neurons.sum()  \n",
    "\n",
    "            loss_regul = loss_struc + loss_func\n",
    "\n",
    "            if epoch <= epochs_train * dag_start_rate:\n",
    "                loss = loss_gen + loss_regul\n",
    "            else:\n",
    "                filters = sampler_graph.get_proba()\n",
    "                loss = loss_gen + loss_regul + (\n",
    "                    (epoch - epochs_train * dag_start_rate) * dag_penalization_increase\n",
    "                ) * notears_constr(filters * filters)\n",
    "\n",
    "            if epoch >= epochs_train:\n",
    "                output.add_(filters.data)\n",
    "                output_loss.add_(loss_gen.data)\n",
    "            else:\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer_gen.step()\n",
    "                optimizer_graph.step()\n",
    "                optimizer_neuron.step()\n",
    "\n",
    "            # 進捗の表示\n",
    "            if epoch % 50 == 0:\n",
    "                pbar.set_postfix(\n",
    "                    gen=loss_gen.item()/n_data_col,\n",
    "                    dis=loss_dis.item(),\n",
    "                    egul_loss=loss_regul.item(),\n",
    "                    tot=loss.item()\n",
    "                )\n",
    "\n",
    "    return output.cpu().numpy()/epochs_test, output_loss.cpu().numpy()/epochs_test/n_data_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_layer_gen = 200\n",
    "n_hidden_layer_dis = 200\n",
    "n_hidden_layers_dis = 2\n",
    "lr_gen = 0.01 * 0.5\n",
    "lr_dis = 0.01 * 0.5 * 2\n",
    "dag_start_rate = 0.5\n",
    "dag_penalization_increase = 0.001 * 10\n",
    "epochs_train = 10000\n",
    "epochs_test = 1000\n",
    "lambda1 = 5.0 * 20\n",
    "lambda2 = 0.005 * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = make_data(n_data=2000)\n",
    "learning_data = data.copy()\n",
    "learning_data.loc[:, :] = scale(learning_data.values) \n",
    "\n",
    "data = learning_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data_col = data.shape[1]\n",
    "data = torch.from_numpy(data.values.astype('float32'))\n",
    "batch_size = len(data)\n",
    "\n",
    "data_iterator = DataLoader(\n",
    "    data, batch_size=batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "\n",
    "sam = SAMGenerator(n_data_col, n_hidden_layer_gen)\n",
    "sam.reset_parameters()\n",
    "sampler_graph = MatrixSampler(n_data_col, mask=None, gumbel=False)\n",
    "sampler_neuron = MatrixSampler((n_hidden_layer_gen, n_data_col), mask=False, gumbel=True)\n",
    "\n",
    "sampler_graph.weights.data.fill_(2)\n",
    "\n",
    "discriminator = SAMDiscriminator(\n",
    "    n_data_col=n_data_col, n_hidden_layer=n_hidden_layer_dis, n_hidden_layers=n_hidden_layers_dis\n",
    ")\n",
    "discriminator.reset_parameters()  \n",
    "\n",
    "optimizer_gen = optim.Adam(sam.parameters(), lr=lr_gen)\n",
    "optimizer_dis = optim.Adam(discriminator.parameters(), lr=lr_dis)\n",
    "optimizer_graph = optim.Adam(sampler_graph.parameters(), lr=lr_gen)\n",
    "optimizer_neuron = optim.Adam(sampler_neuron.parameters(), lr=lr_gen)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "_true = torch.ones(1)\n",
    "_false = torch.zeros(1)\n",
    "\n",
    "noise = torch.randn(batch_size, n_data_col)\n",
    "noise_row = torch.ones(1, n_data_col)\n",
    "\n",
    "output = torch.zeros(n_data_col, n_data_col)\n",
    "output_loss = torch.zeros(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0.00 0.98 0.98 0.98 0.98]\n",
      " [0.98 0.00 0.98 0.98 0.98]\n",
      " [0.98 0.98 0.00 0.98 0.98]\n",
      " [0.98 0.98 0.98 0.00 0.98]\n",
      " [0.98 0.98 0.98 0.98 0.00]]\n",
      "\n",
      "[10/ 11000] Loss Dis: 1.40, Loss Gen: 4.00 , 2[s]\n",
      "[20/ 11000] Loss Dis: 1.39, Loss Gen: 3.32 , 2[s]\n",
      "[30/ 11000] Loss Dis: 1.38, Loss Gen: 3.47 , 2[s]\n",
      "[40/ 11000] Loss Dis: 1.38, Loss Gen: 3.57 , 2[s]\n",
      "[50/ 11000] Loss Dis: 1.38, Loss Gen: 3.46 , 2[s]\n",
      "[60/ 11000] Loss Dis: 1.38, Loss Gen: 3.48 , 2[s]\n",
      "[70/ 11000] Loss Dis: 1.38, Loss Gen: 3.47 , 2[s]\n",
      "[80/ 11000] Loss Dis: 1.38, Loss Gen: 3.50 , 2[s]\n",
      "[90/ 11000] Loss Dis: 1.38, Loss Gen: 3.52 , 2[s]\n",
      "[100/ 11000] Loss Dis: 1.38, Loss Gen: 3.47 , 2[s]\n",
      "\n",
      "[[0.00 0.96 0.97 0.97 0.96]\n",
      " [0.96 0.00 0.96 0.97 0.96]\n",
      " [0.96 0.97 0.00 0.97 0.97]\n",
      " [0.97 0.97 0.97 0.00 0.97]\n",
      " [0.97 0.96 0.97 0.96 0.00]]\n",
      "\n",
      "[110/ 11000] Loss Dis: 1.38, Loss Gen: 3.47 , 2[s]\n",
      "[120/ 11000] Loss Dis: 1.38, Loss Gen: 3.49 , 2[s]\n",
      "[130/ 11000] Loss Dis: 1.37, Loss Gen: 3.59 , 2[s]\n",
      "[140/ 11000] Loss Dis: 1.38, Loss Gen: 3.50 , 2[s]\n",
      "[150/ 11000] Loss Dis: 1.37, Loss Gen: 3.53 , 2[s]\n",
      "[160/ 11000] Loss Dis: 1.38, Loss Gen: 3.50 , 2[s]\n",
      "[170/ 11000] Loss Dis: 1.37, Loss Gen: 3.55 , 2[s]\n",
      "[180/ 11000] Loss Dis: 1.37, Loss Gen: 3.60 , 2[s]\n",
      "[190/ 11000] Loss Dis: 1.38, Loss Gen: 3.51 , 2[s]\n",
      "[200/ 11000] Loss Dis: 1.36, Loss Gen: 3.59 , 2[s]\n",
      "\n",
      "[[0.00 0.92 0.94 0.92 0.91]\n",
      " [0.92 0.00 0.93 0.92 0.91]\n",
      " [0.92 0.94 0.00 0.92 0.92]\n",
      " [0.91 0.92 0.93 0.00 0.93]\n",
      " [0.92 0.92 0.93 0.93 0.00]]\n",
      "\n",
      "[210/ 11000] Loss Dis: 1.37, Loss Gen: 3.60 , 2[s]\n",
      "[220/ 11000] Loss Dis: 1.35, Loss Gen: 3.76 , 2[s]\n",
      "[230/ 11000] Loss Dis: 1.36, Loss Gen: 3.43 , 2[s]\n",
      "[240/ 11000] Loss Dis: 1.37, Loss Gen: 3.51 , 2[s]\n",
      "[250/ 11000] Loss Dis: 1.37, Loss Gen: 3.59 , 2[s]\n",
      "[260/ 11000] Loss Dis: 1.35, Loss Gen: 3.72 , 2[s]\n",
      "[270/ 11000] Loss Dis: 1.35, Loss Gen: 3.78 , 2[s]\n",
      "[280/ 11000] Loss Dis: 1.32, Loss Gen: 3.86 , 2[s]\n",
      "[290/ 11000] Loss Dis: 1.33, Loss Gen: 3.95 , 2[s]\n",
      "[300/ 11000] Loss Dis: 1.33, Loss Gen: 4.08 , 2[s]\n",
      "\n",
      "[[0.00 0.87 0.87 0.81 0.87]\n",
      " [0.87 0.00 0.94 0.78 0.78]\n",
      " [0.85 0.88 0.00 0.79 0.77]\n",
      " [0.78 0.78 0.84 0.00 0.83]\n",
      " [0.86 0.82 0.81 0.83 0.00]]\n",
      "\n",
      "[310/ 11000] Loss Dis: 1.35, Loss Gen: 3.72 , 2[s]\n",
      "[320/ 11000] Loss Dis: 1.33, Loss Gen: 4.30 , 2[s]\n",
      "[330/ 11000] Loss Dis: 1.32, Loss Gen: 3.83 , 2[s]\n",
      "[340/ 11000] Loss Dis: 1.26, Loss Gen: 4.13 , 2[s]\n",
      "[350/ 11000] Loss Dis: 1.34, Loss Gen: 4.55 , 2[s]\n",
      "[360/ 11000] Loss Dis: 1.26, Loss Gen: 4.11 , 2[s]\n",
      "[370/ 11000] Loss Dis: 1.11, Loss Gen: 6.03 , 2[s]\n",
      "[380/ 11000] Loss Dis: 1.20, Loss Gen: 4.69 , 3[s]\n",
      "[390/ 11000] Loss Dis: 1.22, Loss Gen: 4.43 , 3[s]\n",
      "[400/ 11000] Loss Dis: 1.14, Loss Gen: 5.39 , 2[s]\n",
      "\n",
      "[[0.00 0.87 0.90 0.58 0.92]\n",
      " [0.87 0.00 0.92 0.53 0.57]\n",
      " [0.86 0.90 0.00 0.54 0.52]\n",
      " [0.58 0.53 0.69 0.00 0.59]\n",
      " [0.90 0.66 0.72 0.61 0.00]]\n",
      "\n",
      "[410/ 11000] Loss Dis: 1.15, Loss Gen: 6.19 , 3[s]\n",
      "[420/ 11000] Loss Dis: 1.19, Loss Gen: 6.00 , 3[s]\n",
      "[430/ 11000] Loss Dis: 1.19, Loss Gen: 6.19 , 3[s]\n",
      "[440/ 11000] Loss Dis: 1.31, Loss Gen: 5.64 , 3[s]\n",
      "[450/ 11000] Loss Dis: 0.97, Loss Gen: 7.21 , 3[s]\n",
      "[460/ 11000] Loss Dis: 1.19, Loss Gen: 6.18 , 3[s]\n",
      "[470/ 11000] Loss Dis: 1.11, Loss Gen: 6.05 , 3[s]\n",
      "[480/ 11000] Loss Dis: 1.08, Loss Gen: 7.47 , 2[s]\n",
      "[490/ 11000] Loss Dis: 0.98, Loss Gen: 7.90 , 2[s]\n",
      "[500/ 11000] Loss Dis: 0.99, Loss Gen: 8.06 , 2[s]\n",
      "\n",
      "[[0.00 0.89 0.93 0.40 0.94]\n",
      " [0.88 0.00 0.89 0.35 0.41]\n",
      " [0.89 0.91 0.00 0.34 0.35]\n",
      " [0.41 0.35 0.60 0.00 0.31]\n",
      " [0.92 0.56 0.71 0.37 0.00]]\n",
      "\n",
      "[510/ 11000] Loss Dis: 0.91, Loss Gen: 9.07 , 2[s]\n",
      "[520/ 11000] Loss Dis: 0.97, Loss Gen: 9.56 , 2[s]\n",
      "[530/ 11000] Loss Dis: 1.04, Loss Gen: 10.09 , 2[s]\n",
      "[540/ 11000] Loss Dis: 1.06, Loss Gen: 7.73 , 2[s]\n",
      "[550/ 11000] Loss Dis: 0.82, Loss Gen: 9.29 , 2[s]\n",
      "[560/ 11000] Loss Dis: 0.99, Loss Gen: 9.20 , 2[s]\n",
      "[570/ 11000] Loss Dis: 1.07, Loss Gen: 8.67 , 3[s]\n",
      "[580/ 11000] Loss Dis: 1.20, Loss Gen: 4.57 , 3[s]\n",
      "[590/ 11000] Loss Dis: 1.02, Loss Gen: 9.02 , 3[s]\n",
      "[600/ 11000] Loss Dis: 1.23, Loss Gen: 5.78 , 3[s]\n",
      "\n",
      "[[0.00 0.88 0.94 0.34 0.95]\n",
      " [0.90 0.00 0.86 0.30 0.31]\n",
      " [0.91 0.93 0.00 0.35 0.24]\n",
      " [0.30 0.29 0.60 0.00 0.22]\n",
      " [0.94 0.46 0.68 0.26 0.00]]\n",
      "\n",
      "[610/ 11000] Loss Dis: 1.06, Loss Gen: 10.01 , 3[s]\n",
      "[620/ 11000] Loss Dis: 0.76, Loss Gen: 15.11 , 3[s]\n",
      "[630/ 11000] Loss Dis: 0.83, Loss Gen: 10.47 , 2[s]\n",
      "[640/ 11000] Loss Dis: 0.84, Loss Gen: 14.52 , 3[s]\n",
      "[650/ 11000] Loss Dis: 0.89, Loss Gen: 13.63 , 3[s]\n",
      "[660/ 11000] Loss Dis: 0.75, Loss Gen: 13.14 , 3[s]\n",
      "[670/ 11000] Loss Dis: 0.78, Loss Gen: 11.21 , 3[s]\n",
      "[680/ 11000] Loss Dis: 0.89, Loss Gen: 11.65 , 3[s]\n",
      "[690/ 11000] Loss Dis: 0.90, Loss Gen: 11.39 , 2[s]\n",
      "[700/ 11000] Loss Dis: 1.06, Loss Gen: 6.61 , 3[s]\n",
      "\n",
      "[[0.00 0.87 0.95 0.30 0.96]\n",
      " [0.90 0.00 0.82 0.23 0.26]\n",
      " [0.92 0.94 0.00 0.35 0.19]\n",
      " [0.24 0.27 0.65 0.00 0.16]\n",
      " [0.95 0.34 0.64 0.26 0.00]]\n",
      "\n",
      "[710/ 11000] Loss Dis: 0.93, Loss Gen: 12.11 , 2[s]\n",
      "[720/ 11000] Loss Dis: 0.99, Loss Gen: 8.38 , 2[s]\n",
      "[730/ 11000] Loss Dis: 0.77, Loss Gen: 13.97 , 2[s]\n",
      "[740/ 11000] Loss Dis: 0.85, Loss Gen: 10.12 , 2[s]\n",
      "[750/ 11000] Loss Dis: 1.15, Loss Gen: 10.32 , 2[s]\n",
      "[760/ 11000] Loss Dis: 0.76, Loss Gen: 10.64 , 2[s]\n",
      "[770/ 11000] Loss Dis: 0.84, Loss Gen: 12.92 , 2[s]\n",
      "[780/ 11000] Loss Dis: 0.85, Loss Gen: 12.78 , 2[s]\n",
      "[790/ 11000] Loss Dis: 0.94, Loss Gen: 9.89 , 2[s]\n",
      "[800/ 11000] Loss Dis: 0.89, Loss Gen: 11.84 , 2[s]\n",
      "\n",
      "[[0.00 0.86 0.95 0.28 0.96]\n",
      " [0.91 0.00 0.82 0.23 0.21]\n",
      " [0.92 0.95 0.00 0.36 0.15]\n",
      " [0.22 0.23 0.63 0.00 0.11]\n",
      " [0.96 0.33 0.66 0.22 0.00]]\n",
      "\n",
      "[810/ 11000] Loss Dis: 1.01, Loss Gen: 12.27 , 2[s]\n",
      "[820/ 11000] Loss Dis: 0.85, Loss Gen: 13.76 , 2[s]\n",
      "[830/ 11000] Loss Dis: 0.72, Loss Gen: 15.80 , 2[s]\n",
      "[840/ 11000] Loss Dis: 0.62, Loss Gen: 13.30 , 2[s]\n",
      "[850/ 11000] Loss Dis: 1.12, Loss Gen: 11.51 , 2[s]\n",
      "[860/ 11000] Loss Dis: 0.98, Loss Gen: 7.86 , 2[s]\n",
      "[870/ 11000] Loss Dis: 0.85, Loss Gen: 10.66 , 2[s]\n",
      "[880/ 11000] Loss Dis: 0.64, Loss Gen: 15.85 , 2[s]\n",
      "[890/ 11000] Loss Dis: 0.91, Loss Gen: 13.44 , 2[s]\n",
      "[900/ 11000] Loss Dis: 1.04, Loss Gen: 15.50 , 2[s]\n",
      "\n",
      "[[0.00 0.87 0.95 0.23 0.97]\n",
      " [0.91 0.00 0.82 0.20 0.18]\n",
      " [0.92 0.95 0.00 0.32 0.11]\n",
      " [0.18 0.19 0.63 0.00 0.10]\n",
      " [0.96 0.29 0.65 0.20 0.00]]\n",
      "\n",
      "[910/ 11000] Loss Dis: 1.00, Loss Gen: 11.22 , 2[s]\n",
      "[920/ 11000] Loss Dis: 0.97, Loss Gen: 9.49 , 2[s]\n",
      "[930/ 11000] Loss Dis: 0.64, Loss Gen: 12.71 , 2[s]\n",
      "[940/ 11000] Loss Dis: 0.90, Loss Gen: 8.21 , 2[s]\n",
      "[950/ 11000] Loss Dis: 0.75, Loss Gen: 11.42 , 2[s]\n",
      "[960/ 11000] Loss Dis: 0.70, Loss Gen: 13.64 , 2[s]\n",
      "[970/ 11000] Loss Dis: 0.72, Loss Gen: 18.04 , 2[s]\n",
      "[980/ 11000] Loss Dis: 0.76, Loss Gen: 21.93 , 2[s]\n",
      "[990/ 11000] Loss Dis: 0.84, Loss Gen: 11.83 , 2[s]\n",
      "[1000/ 11000] Loss Dis: 1.08, Loss Gen: 9.36 , 2[s]\n",
      "\n",
      "[[0.00 0.86 0.96 0.19 0.97]\n",
      " [0.92 0.00 0.83 0.17 0.15]\n",
      " [0.92 0.96 0.00 0.35 0.08]\n",
      " [0.16 0.16 0.61 0.00 0.07]\n",
      " [0.97 0.27 0.63 0.21 0.00]]\n",
      "\n",
      "[1010/ 11000] Loss Dis: 1.05, Loss Gen: 12.20 , 2[s]\n",
      "[1020/ 11000] Loss Dis: 0.80, Loss Gen: 9.75 , 2[s]\n",
      "[1030/ 11000] Loss Dis: 0.98, Loss Gen: 12.94 , 2[s]\n",
      "[1040/ 11000] Loss Dis: 0.96, Loss Gen: 9.12 , 2[s]\n",
      "[1050/ 11000] Loss Dis: 1.14, Loss Gen: 10.99 , 2[s]\n",
      "[1060/ 11000] Loss Dis: 0.61, Loss Gen: 12.99 , 2[s]\n",
      "[1070/ 11000] Loss Dis: 1.00, Loss Gen: 9.18 , 3[s]\n",
      "[1080/ 11000] Loss Dis: 0.76, Loss Gen: 13.85 , 3[s]\n",
      "[1090/ 11000] Loss Dis: 0.74, Loss Gen: 15.15 , 3[s]\n",
      "[1100/ 11000] Loss Dis: 0.79, Loss Gen: 16.15 , 3[s]\n",
      "\n",
      "[[0.00 0.88 0.97 0.16 0.97]\n",
      " [0.92 0.00 0.85 0.14 0.13]\n",
      " [0.92 0.96 0.00 0.36 0.05]\n",
      " [0.15 0.16 0.61 0.00 0.06]\n",
      " [0.97 0.27 0.58 0.19 0.00]]\n",
      "\n",
      "[1110/ 11000] Loss Dis: 0.74, Loss Gen: 18.02 , 3[s]\n",
      "[1120/ 11000] Loss Dis: 0.66, Loss Gen: 20.11 , 3[s]\n",
      "[1130/ 11000] Loss Dis: 0.81, Loss Gen: 14.55 , 3[s]\n",
      "[1140/ 11000] Loss Dis: 1.05, Loss Gen: 11.76 , 3[s]\n",
      "[1150/ 11000] Loss Dis: 0.90, Loss Gen: 15.92 , 3[s]\n",
      "[1160/ 11000] Loss Dis: 0.75, Loss Gen: 12.12 , 3[s]\n",
      "[1170/ 11000] Loss Dis: 0.82, Loss Gen: 10.44 , 3[s]\n",
      "[1180/ 11000] Loss Dis: 0.94, Loss Gen: 12.09 , 3[s]\n",
      "[1190/ 11000] Loss Dis: 0.58, Loss Gen: 20.59 , 3[s]\n",
      "[1200/ 11000] Loss Dis: 0.86, Loss Gen: 18.51 , 3[s]\n",
      "\n",
      "[[0.00 0.88 0.97 0.13 0.97]\n",
      " [0.93 0.00 0.85 0.10 0.10]\n",
      " [0.92 0.96 0.00 0.39 0.05]\n",
      " [0.15 0.14 0.57 0.00 0.06]\n",
      " [0.98 0.26 0.50 0.15 0.00]]\n",
      "\n",
      "[1210/ 11000] Loss Dis: 1.06, Loss Gen: 12.53 , 3[s]\n",
      "[1220/ 11000] Loss Dis: 0.82, Loss Gen: 9.55 , 2[s]\n",
      "[1230/ 11000] Loss Dis: 0.75, Loss Gen: 16.24 , 2[s]\n",
      "[1240/ 11000] Loss Dis: 0.73, Loss Gen: 21.07 , 2[s]\n",
      "[1250/ 11000] Loss Dis: 1.21, Loss Gen: 15.78 , 2[s]\n",
      "[1260/ 11000] Loss Dis: 0.73, Loss Gen: 17.90 , 2[s]\n",
      "[1270/ 11000] Loss Dis: 1.06, Loss Gen: 11.65 , 2[s]\n",
      "[1280/ 11000] Loss Dis: 0.91, Loss Gen: 10.94 , 2[s]\n",
      "[1290/ 11000] Loss Dis: 0.80, Loss Gen: 12.31 , 2[s]\n",
      "[1300/ 11000] Loss Dis: 0.66, Loss Gen: 21.72 , 2[s]\n",
      "\n",
      "[[0.00 0.88 0.97 0.12 0.98]\n",
      " [0.93 0.00 0.85 0.08 0.08]\n",
      " [0.92 0.97 0.00 0.40 0.05]\n",
      " [0.13 0.12 0.54 0.00 0.06]\n",
      " [0.98 0.25 0.43 0.15 0.00]]\n",
      "\n",
      "[1310/ 11000] Loss Dis: 1.19, Loss Gen: 8.39 , 2[s]\n",
      "[1320/ 11000] Loss Dis: 0.99, Loss Gen: 17.57 , 2[s]\n",
      "[1330/ 11000] Loss Dis: 0.95, Loss Gen: 10.65 , 2[s]\n",
      "[1340/ 11000] Loss Dis: 0.73, Loss Gen: 16.41 , 2[s]\n",
      "[1350/ 11000] Loss Dis: 0.89, Loss Gen: 11.90 , 2[s]\n",
      "[1360/ 11000] Loss Dis: 0.75, Loss Gen: 17.92 , 2[s]\n",
      "[1370/ 11000] Loss Dis: 0.95, Loss Gen: 13.29 , 2[s]\n",
      "[1380/ 11000] Loss Dis: 0.63, Loss Gen: 16.25 , 2[s]\n",
      "[1390/ 11000] Loss Dis: 0.99, Loss Gen: 11.99 , 2[s]\n",
      "[1400/ 11000] Loss Dis: 0.83, Loss Gen: 10.85 , 2[s]\n",
      "\n",
      "[[0.00 0.89 0.97 0.11 0.98]\n",
      " [0.94 0.00 0.85 0.08 0.08]\n",
      " [0.92 0.97 0.00 0.40 0.06]\n",
      " [0.12 0.11 0.51 0.00 0.06]\n",
      " [0.98 0.22 0.40 0.16 0.00]]\n",
      "\n",
      "[1410/ 11000] Loss Dis: 0.93, Loss Gen: 7.21 , 2[s]\n",
      "[1420/ 11000] Loss Dis: 0.67, Loss Gen: 15.16 , 2[s]\n",
      "[1430/ 11000] Loss Dis: 1.01, Loss Gen: 16.94 , 2[s]\n",
      "[1440/ 11000] Loss Dis: 0.90, Loss Gen: 11.72 , 2[s]\n",
      "[1450/ 11000] Loss Dis: 1.14, Loss Gen: 9.04 , 2[s]\n",
      "[1460/ 11000] Loss Dis: 0.92, Loss Gen: 20.27 , 2[s]\n",
      "[1470/ 11000] Loss Dis: 0.97, Loss Gen: 21.09 , 2[s]\n",
      "[1480/ 11000] Loss Dis: 1.08, Loss Gen: 7.35 , 3[s]\n",
      "[1490/ 11000] Loss Dis: 0.87, Loss Gen: 14.06 , 3[s]\n",
      "[1500/ 11000] Loss Dis: 0.88, Loss Gen: 16.61 , 3[s]\n",
      "\n",
      "[[0.00 0.90 0.97 0.12 0.98]\n",
      " [0.93 0.00 0.84 0.08 0.07]\n",
      " [0.93 0.97 0.00 0.38 0.05]\n",
      " [0.11 0.09 0.49 0.00 0.06]\n",
      " [0.98 0.22 0.38 0.15 0.00]]\n",
      "\n",
      "[1510/ 11000] Loss Dis: 1.03, Loss Gen: 10.06 , 3[s]\n",
      "[1520/ 11000] Loss Dis: 0.82, Loss Gen: 10.08 , 3[s]\n",
      "[1530/ 11000] Loss Dis: 1.14, Loss Gen: 6.53 , 3[s]\n",
      "[1540/ 11000] Loss Dis: 0.77, Loss Gen: 16.59 , 3[s]\n",
      "[1550/ 11000] Loss Dis: 0.99, Loss Gen: 8.21 , 3[s]\n",
      "[1560/ 11000] Loss Dis: 1.04, Loss Gen: 9.07 , 3[s]\n",
      "[1570/ 11000] Loss Dis: 1.12, Loss Gen: 11.19 , 3[s]\n",
      "[1580/ 11000] Loss Dis: 0.84, Loss Gen: 17.40 , 3[s]\n",
      "[1590/ 11000] Loss Dis: 1.01, Loss Gen: 8.03 , 3[s]\n",
      "[1600/ 11000] Loss Dis: 0.90, Loss Gen: 17.78 , 3[s]\n",
      "\n",
      "[[0.00 0.91 0.97 0.14 0.98]\n",
      " [0.94 0.00 0.84 0.06 0.07]\n",
      " [0.93 0.97 0.00 0.41 0.06]\n",
      " [0.10 0.08 0.45 0.00 0.05]\n",
      " [0.98 0.21 0.35 0.13 0.00]]\n",
      "\n",
      "[1610/ 11000] Loss Dis: 0.90, Loss Gen: 11.62 , 3[s]\n",
      "[1620/ 11000] Loss Dis: 0.96, Loss Gen: 12.21 , 3[s]\n",
      "[1630/ 11000] Loss Dis: 0.77, Loss Gen: 12.64 , 2[s]\n",
      "[1640/ 11000] Loss Dis: 0.92, Loss Gen: 13.67 , 2[s]\n",
      "[1650/ 11000] Loss Dis: 0.94, Loss Gen: 17.13 , 2[s]\n",
      "[1660/ 11000] Loss Dis: 1.13, Loss Gen: 6.07 , 3[s]\n",
      "[1670/ 11000] Loss Dis: 0.68, Loss Gen: 13.41 , 2[s]\n",
      "[1680/ 11000] Loss Dis: 0.97, Loss Gen: 9.50 , 2[s]\n",
      "[1690/ 11000] Loss Dis: 0.72, Loss Gen: 14.10 , 2[s]\n",
      "[1700/ 11000] Loss Dis: 0.75, Loss Gen: 15.94 , 2[s]\n",
      "\n",
      "[[0.00 0.92 0.97 0.15 0.98]\n",
      " [0.94 0.00 0.85 0.06 0.06]\n",
      " [0.94 0.97 0.00 0.43 0.06]\n",
      " [0.11 0.07 0.43 0.00 0.05]\n",
      " [0.99 0.20 0.34 0.12 0.00]]\n",
      "\n",
      "[1710/ 11000] Loss Dis: 1.03, Loss Gen: 11.38 , 2[s]\n",
      "[1720/ 11000] Loss Dis: 1.09, Loss Gen: 8.22 , 2[s]\n",
      "[1730/ 11000] Loss Dis: 1.06, Loss Gen: 15.10 , 2[s]\n",
      "[1740/ 11000] Loss Dis: 1.17, Loss Gen: 7.63 , 2[s]\n",
      "[1750/ 11000] Loss Dis: 1.11, Loss Gen: 5.75 , 2[s]\n",
      "[1760/ 11000] Loss Dis: 0.98, Loss Gen: 12.72 , 2[s]\n",
      "[1770/ 11000] Loss Dis: 0.94, Loss Gen: 7.25 , 2[s]\n",
      "[1780/ 11000] Loss Dis: 0.91, Loss Gen: 7.09 , 2[s]\n",
      "[1790/ 11000] Loss Dis: 1.11, Loss Gen: 8.88 , 2[s]\n",
      "[1800/ 11000] Loss Dis: 0.83, Loss Gen: 14.38 , 2[s]\n",
      "\n",
      "[[0.00 0.92 0.97 0.15 0.99]\n",
      " [0.94 0.00 0.85 0.06 0.06]\n",
      " [0.94 0.97 0.00 0.44 0.05]\n",
      " [0.09 0.06 0.41 0.00 0.05]\n",
      " [0.99 0.18 0.29 0.14 0.00]]\n",
      "\n",
      "[1810/ 11000] Loss Dis: 0.82, Loss Gen: 14.97 , 2[s]\n",
      "[1820/ 11000] Loss Dis: 0.78, Loss Gen: 12.59 , 2[s]\n",
      "[1830/ 11000] Loss Dis: 0.89, Loss Gen: 8.59 , 2[s]\n",
      "[1840/ 11000] Loss Dis: 0.70, Loss Gen: 13.77 , 2[s]\n",
      "[1850/ 11000] Loss Dis: 0.97, Loss Gen: 13.80 , 2[s]\n",
      "[1860/ 11000] Loss Dis: 0.98, Loss Gen: 13.38 , 2[s]\n",
      "[1870/ 11000] Loss Dis: 0.89, Loss Gen: 13.49 , 2[s]\n",
      "[1880/ 11000] Loss Dis: 1.17, Loss Gen: 9.73 , 2[s]\n",
      "[1890/ 11000] Loss Dis: 0.70, Loss Gen: 19.52 , 2[s]\n",
      "[1900/ 11000] Loss Dis: 0.84, Loss Gen: 12.75 , 2[s]\n",
      "\n",
      "[[0.00 0.93 0.96 0.17 0.99]\n",
      " [0.95 0.00 0.86 0.05 0.05]\n",
      " [0.94 0.97 0.00 0.43 0.05]\n",
      " [0.08 0.06 0.38 0.00 0.04]\n",
      " [0.99 0.18 0.27 0.17 0.00]]\n",
      "\n",
      "[1910/ 11000] Loss Dis: 0.84, Loss Gen: 18.25 , 2[s]\n",
      "[1920/ 11000] Loss Dis: 1.02, Loss Gen: 9.60 , 2[s]\n",
      "[1930/ 11000] Loss Dis: 0.91, Loss Gen: 11.96 , 2[s]\n",
      "[1940/ 11000] Loss Dis: 1.18, Loss Gen: 5.38 , 2[s]\n",
      "[1950/ 11000] Loss Dis: 0.79, Loss Gen: 14.45 , 2[s]\n",
      "[1960/ 11000] Loss Dis: 0.92, Loss Gen: 19.97 , 2[s]\n",
      "[1970/ 11000] Loss Dis: 1.00, Loss Gen: 11.29 , 2[s]\n",
      "[1980/ 11000] Loss Dis: 1.01, Loss Gen: 14.38 , 2[s]\n",
      "[1990/ 11000] Loss Dis: 0.70, Loss Gen: 17.20 , 2[s]\n",
      "[2000/ 11000] Loss Dis: 0.95, Loss Gen: 15.86 , 2[s]\n",
      "\n",
      "[[0.00 0.92 0.96 0.17 0.99]\n",
      " [0.95 0.00 0.85 0.04 0.06]\n",
      " [0.94 0.98 0.00 0.40 0.04]\n",
      " [0.07 0.05 0.37 0.00 0.03]\n",
      " [0.99 0.15 0.24 0.18 0.00]]\n",
      "\n",
      "[2010/ 11000] Loss Dis: 1.24, Loss Gen: 6.78 , 2[s]\n",
      "[2020/ 11000] Loss Dis: 0.93, Loss Gen: 9.91 , 3[s]\n",
      "[2030/ 11000] Loss Dis: 0.71, Loss Gen: 16.13 , 3[s]\n",
      "[2040/ 11000] Loss Dis: 0.76, Loss Gen: 17.44 , 3[s]\n",
      "[2050/ 11000] Loss Dis: 1.01, Loss Gen: 10.49 , 3[s]\n",
      "[2060/ 11000] Loss Dis: 1.05, Loss Gen: 11.26 , 3[s]\n",
      "[2070/ 11000] Loss Dis: 0.96, Loss Gen: 10.61 , 3[s]\n",
      "[2080/ 11000] Loss Dis: 1.01, Loss Gen: 10.05 , 2[s]\n",
      "[2090/ 11000] Loss Dis: 1.37, Loss Gen: 9.87 , 2[s]\n",
      "[2100/ 11000] Loss Dis: 1.03, Loss Gen: 11.71 , 3[s]\n",
      "\n",
      "[[0.00 0.92 0.96 0.19 0.99]\n",
      " [0.96 0.00 0.85 0.04 0.05]\n",
      " [0.96 0.98 0.00 0.39 0.05]\n",
      " [0.08 0.05 0.34 0.00 0.03]\n",
      " [0.99 0.14 0.21 0.19 0.00]]\n",
      "\n",
      "[2110/ 11000] Loss Dis: 1.25, Loss Gen: 5.64 , 3[s]\n",
      "[2120/ 11000] Loss Dis: 1.08, Loss Gen: 7.09 , 2[s]\n",
      "[2130/ 11000] Loss Dis: 1.31, Loss Gen: 6.59 , 2[s]\n",
      "[2140/ 11000] Loss Dis: 1.11, Loss Gen: 6.65 , 2[s]\n",
      "[2150/ 11000] Loss Dis: 1.01, Loss Gen: 8.45 , 2[s]\n",
      "[2160/ 11000] Loss Dis: 0.81, Loss Gen: 16.87 , 2[s]\n",
      "[2170/ 11000] Loss Dis: 0.80, Loss Gen: 12.62 , 2[s]\n",
      "[2180/ 11000] Loss Dis: 0.95, Loss Gen: 12.14 , 2[s]\n",
      "[2190/ 11000] Loss Dis: 0.80, Loss Gen: 11.08 , 2[s]\n",
      "[2200/ 11000] Loss Dis: 1.21, Loss Gen: 7.47 , 2[s]\n",
      "\n",
      "[[0.00 0.92 0.97 0.21 0.99]\n",
      " [0.96 0.00 0.84 0.04 0.06]\n",
      " [0.96 0.98 0.00 0.39 0.06]\n",
      " [0.06 0.04 0.33 0.00 0.03]\n",
      " [0.99 0.14 0.19 0.19 0.00]]\n",
      "\n",
      "[2210/ 11000] Loss Dis: 0.67, Loss Gen: 22.82 , 2[s]\n",
      "[2220/ 11000] Loss Dis: 1.18, Loss Gen: 7.17 , 2[s]\n",
      "[2230/ 11000] Loss Dis: 1.10, Loss Gen: 7.95 , 2[s]\n",
      "[2240/ 11000] Loss Dis: 1.21, Loss Gen: 6.92 , 2[s]\n",
      "[2250/ 11000] Loss Dis: 1.01, Loss Gen: 14.91 , 2[s]\n",
      "[2260/ 11000] Loss Dis: 1.01, Loss Gen: 8.99 , 2[s]\n",
      "[2270/ 11000] Loss Dis: 1.16, Loss Gen: 9.82 , 2[s]\n",
      "[2280/ 11000] Loss Dis: 0.90, Loss Gen: 15.10 , 2[s]\n",
      "[2290/ 11000] Loss Dis: 1.05, Loss Gen: 7.58 , 3[s]\n",
      "[2300/ 11000] Loss Dis: 0.86, Loss Gen: 17.95 , 2[s]\n",
      "\n",
      "[[0.00 0.93 0.97 0.21 0.99]\n",
      " [0.96 0.00 0.83 0.03 0.05]\n",
      " [0.96 0.98 0.00 0.40 0.06]\n",
      " [0.05 0.04 0.33 0.00 0.03]\n",
      " [0.99 0.14 0.16 0.20 0.00]]\n",
      "\n",
      "[2310/ 11000] Loss Dis: 0.96, Loss Gen: 10.73 , 2[s]\n",
      "[2320/ 11000] Loss Dis: 0.91, Loss Gen: 10.62 , 2[s]\n",
      "[2330/ 11000] Loss Dis: 1.09, Loss Gen: 12.44 , 2[s]\n",
      "[2340/ 11000] Loss Dis: 1.26, Loss Gen: 6.04 , 2[s]\n",
      "[2350/ 11000] Loss Dis: 1.02, Loss Gen: 10.80 , 2[s]\n",
      "[2360/ 11000] Loss Dis: 0.94, Loss Gen: 14.65 , 2[s]\n",
      "[2370/ 11000] Loss Dis: 0.92, Loss Gen: 16.22 , 2[s]\n",
      "[2380/ 11000] Loss Dis: 1.19, Loss Gen: 5.56 , 2[s]\n",
      "[2390/ 11000] Loss Dis: 1.00, Loss Gen: 16.61 , 2[s]\n",
      "[2400/ 11000] Loss Dis: 0.86, Loss Gen: 18.40 , 2[s]\n",
      "\n",
      "[[0.00 0.93 0.96 0.21 0.99]\n",
      " [0.96 0.00 0.81 0.03 0.05]\n",
      " [0.96 0.98 0.00 0.40 0.06]\n",
      " [0.05 0.03 0.33 0.00 0.03]\n",
      " [0.99 0.14 0.15 0.18 0.00]]\n",
      "\n",
      "[2410/ 11000] Loss Dis: 1.21, Loss Gen: 5.30 , 2[s]\n",
      "[2420/ 11000] Loss Dis: 0.79, Loss Gen: 13.80 , 2[s]\n",
      "[2430/ 11000] Loss Dis: 1.30, Loss Gen: 4.93 , 2[s]\n",
      "[2440/ 11000] Loss Dis: 1.07, Loss Gen: 7.10 , 2[s]\n",
      "[2450/ 11000] Loss Dis: 1.18, Loss Gen: 5.98 , 2[s]\n",
      "[2460/ 11000] Loss Dis: 0.82, Loss Gen: 17.46 , 2[s]\n",
      "[2470/ 11000] Loss Dis: 0.92, Loss Gen: 14.90 , 3[s]\n",
      "[2480/ 11000] Loss Dis: 0.83, Loss Gen: 16.50 , 3[s]\n",
      "[2490/ 11000] Loss Dis: 0.88, Loss Gen: 16.43 , 2[s]\n",
      "[2500/ 11000] Loss Dis: 0.94, Loss Gen: 9.58 , 2[s]\n",
      "\n",
      "[[0.00 0.94 0.96 0.23 0.99]\n",
      " [0.96 0.00 0.79 0.03 0.05]\n",
      " [0.96 0.98 0.00 0.37 0.06]\n",
      " [0.04 0.03 0.32 0.00 0.03]\n",
      " [0.99 0.13 0.14 0.17 0.00]]\n",
      "\n",
      "[2510/ 11000] Loss Dis: 0.88, Loss Gen: 10.21 , 3[s]\n",
      "[2520/ 11000] Loss Dis: 0.89, Loss Gen: 12.71 , 2[s]\n",
      "[2530/ 11000] Loss Dis: 1.24, Loss Gen: 6.61 , 2[s]\n",
      "[2540/ 11000] Loss Dis: 1.17, Loss Gen: 15.20 , 3[s]\n",
      "[2550/ 11000] Loss Dis: 0.94, Loss Gen: 17.95 , 3[s]\n",
      "[2560/ 11000] Loss Dis: 0.94, Loss Gen: 10.39 , 2[s]\n",
      "[2570/ 11000] Loss Dis: 1.08, Loss Gen: 8.40 , 2[s]\n",
      "[2580/ 11000] Loss Dis: 1.16, Loss Gen: 6.39 , 2[s]\n",
      "[2590/ 11000] Loss Dis: 1.13, Loss Gen: 6.03 , 2[s]\n",
      "[2600/ 11000] Loss Dis: 1.23, Loss Gen: 12.88 , 2[s]\n",
      "\n",
      "[[0.00 0.95 0.96 0.23 0.99]\n",
      " [0.95 0.00 0.79 0.03 0.05]\n",
      " [0.97 0.98 0.00 0.36 0.06]\n",
      " [0.04 0.03 0.32 0.00 0.03]\n",
      " [0.99 0.14 0.13 0.16 0.00]]\n",
      "\n",
      "[2610/ 11000] Loss Dis: 1.08, Loss Gen: 8.39 , 3[s]\n",
      "[2620/ 11000] Loss Dis: 0.75, Loss Gen: 17.99 , 2[s]\n",
      "[2630/ 11000] Loss Dis: 1.06, Loss Gen: 12.61 , 2[s]\n",
      "[2640/ 11000] Loss Dis: 1.08, Loss Gen: 9.28 , 2[s]\n",
      "[2650/ 11000] Loss Dis: 0.85, Loss Gen: 16.50 , 2[s]\n",
      "[2660/ 11000] Loss Dis: 1.22, Loss Gen: 4.03 , 2[s]\n",
      "[2670/ 11000] Loss Dis: 1.26, Loss Gen: 10.14 , 2[s]\n",
      "[2680/ 11000] Loss Dis: 0.72, Loss Gen: 19.70 , 2[s]\n",
      "[2690/ 11000] Loss Dis: 1.23, Loss Gen: 7.93 , 2[s]\n",
      "[2700/ 11000] Loss Dis: 1.11, Loss Gen: 6.59 , 2[s]\n",
      "\n",
      "[[0.00 0.95 0.96 0.23 0.99]\n",
      " [0.95 0.00 0.74 0.03 0.05]\n",
      " [0.96 0.98 0.00 0.35 0.06]\n",
      " [0.03 0.02 0.33 0.00 0.02]\n",
      " [0.99 0.13 0.12 0.16 0.00]]\n",
      "\n",
      "[2710/ 11000] Loss Dis: 1.33, Loss Gen: 4.06 , 2[s]\n",
      "[2720/ 11000] Loss Dis: 1.14, Loss Gen: 6.56 , 2[s]\n",
      "[2730/ 11000] Loss Dis: 1.07, Loss Gen: 5.45 , 2[s]\n",
      "[2740/ 11000] Loss Dis: 0.79, Loss Gen: 16.16 , 2[s]\n",
      "[2750/ 11000] Loss Dis: 1.09, Loss Gen: 7.03 , 2[s]\n",
      "[2760/ 11000] Loss Dis: 1.03, Loss Gen: 8.17 , 2[s]\n",
      "[2770/ 11000] Loss Dis: 1.19, Loss Gen: 14.03 , 2[s]\n",
      "[2780/ 11000] Loss Dis: 0.86, Loss Gen: 16.49 , 2[s]\n",
      "[2790/ 11000] Loss Dis: 0.78, Loss Gen: 20.24 , 2[s]\n",
      "[2800/ 11000] Loss Dis: 0.84, Loss Gen: 19.13 , 2[s]\n",
      "\n",
      "[[0.00 0.95 0.96 0.27 0.99]\n",
      " [0.95 0.00 0.72 0.03 0.05]\n",
      " [0.96 0.98 0.00 0.36 0.07]\n",
      " [0.03 0.02 0.33 0.00 0.02]\n",
      " [0.99 0.12 0.12 0.16 0.00]]\n",
      "\n",
      "[2810/ 11000] Loss Dis: 0.96, Loss Gen: 13.24 , 2[s]\n",
      "[2820/ 11000] Loss Dis: 1.26, Loss Gen: 4.28 , 2[s]\n",
      "[2830/ 11000] Loss Dis: 1.05, Loss Gen: 17.42 , 2[s]\n",
      "[2840/ 11000] Loss Dis: 1.01, Loss Gen: 7.27 , 2[s]\n",
      "[2850/ 11000] Loss Dis: 0.94, Loss Gen: 14.88 , 2[s]\n",
      "[2860/ 11000] Loss Dis: 0.87, Loss Gen: 14.16 , 2[s]\n",
      "[2870/ 11000] Loss Dis: 0.89, Loss Gen: 11.24 , 2[s]\n",
      "[2880/ 11000] Loss Dis: 1.20, Loss Gen: 7.02 , 2[s]\n",
      "[2890/ 11000] Loss Dis: 0.94, Loss Gen: 15.94 , 2[s]\n",
      "[2900/ 11000] Loss Dis: 0.91, Loss Gen: 11.87 , 2[s]\n",
      "\n",
      "[[0.00 0.95 0.96 0.26 0.99]\n",
      " [0.95 0.00 0.68 0.02 0.05]\n",
      " [0.96 0.99 0.00 0.37 0.06]\n",
      " [0.03 0.02 0.30 0.00 0.02]\n",
      " [0.99 0.11 0.10 0.17 0.00]]\n",
      "\n",
      "[2910/ 11000] Loss Dis: 1.07, Loss Gen: 13.64 , 2[s]\n",
      "[2920/ 11000] Loss Dis: 1.06, Loss Gen: 7.83 , 2[s]\n",
      "[2930/ 11000] Loss Dis: 1.08, Loss Gen: 14.99 , 2[s]\n",
      "[2940/ 11000] Loss Dis: 0.80, Loss Gen: 20.34 , 2[s]\n",
      "[2950/ 11000] Loss Dis: 1.21, Loss Gen: 5.15 , 2[s]\n",
      "[2960/ 11000] Loss Dis: 1.03, Loss Gen: 13.63 , 2[s]\n",
      "[2970/ 11000] Loss Dis: 0.82, Loss Gen: 17.45 , 2[s]\n",
      "[2980/ 11000] Loss Dis: 0.92, Loss Gen: 13.53 , 2[s]\n",
      "[2990/ 11000] Loss Dis: 1.06, Loss Gen: 10.69 , 2[s]\n",
      "[3000/ 11000] Loss Dis: 1.13, Loss Gen: 5.60 , 2[s]\n",
      "\n",
      "[[0.00 0.96 0.96 0.28 0.99]\n",
      " [0.95 0.00 0.63 0.02 0.04]\n",
      " [0.96 0.98 0.00 0.37 0.06]\n",
      " [0.03 0.02 0.30 0.00 0.03]\n",
      " [0.99 0.11 0.09 0.18 0.00]]\n",
      "\n",
      "[3010/ 11000] Loss Dis: 0.83, Loss Gen: 15.91 , 2[s]\n",
      "[3020/ 11000] Loss Dis: 1.08, Loss Gen: 9.03 , 2[s]\n",
      "[3030/ 11000] Loss Dis: 0.88, Loss Gen: 16.32 , 2[s]\n",
      "[3040/ 11000] Loss Dis: 0.98, Loss Gen: 16.19 , 2[s]\n",
      "[3050/ 11000] Loss Dis: 1.04, Loss Gen: 7.73 , 3[s]\n",
      "[3060/ 11000] Loss Dis: 1.49, Loss Gen: 4.52 , 2[s]\n",
      "[3070/ 11000] Loss Dis: 1.04, Loss Gen: 15.07 , 3[s]\n",
      "[3080/ 11000] Loss Dis: 1.29, Loss Gen: 5.18 , 3[s]\n",
      "[3090/ 11000] Loss Dis: 0.90, Loss Gen: 17.32 , 3[s]\n",
      "[3100/ 11000] Loss Dis: 1.00, Loss Gen: 15.50 , 3[s]\n",
      "\n",
      "[[0.00 0.96 0.95 0.26 0.99]\n",
      " [0.95 0.00 0.60 0.02 0.04]\n",
      " [0.96 0.98 0.00 0.37 0.06]\n",
      " [0.03 0.02 0.29 0.00 0.03]\n",
      " [0.99 0.11 0.08 0.18 0.00]]\n",
      "\n",
      "[3110/ 11000] Loss Dis: 0.98, Loss Gen: 11.40 , 3[s]\n",
      "[3120/ 11000] Loss Dis: 1.01, Loss Gen: 6.40 , 3[s]\n",
      "[3130/ 11000] Loss Dis: 1.00, Loss Gen: 7.27 , 3[s]\n",
      "[3140/ 11000] Loss Dis: 1.11, Loss Gen: 11.81 , 2[s]\n",
      "[3150/ 11000] Loss Dis: 1.09, Loss Gen: 13.75 , 2[s]\n",
      "[3160/ 11000] Loss Dis: 1.12, Loss Gen: 14.44 , 2[s]\n",
      "[3170/ 11000] Loss Dis: 1.04, Loss Gen: 14.32 , 2[s]\n",
      "[3180/ 11000] Loss Dis: 0.85, Loss Gen: 17.47 , 2[s]\n",
      "[3190/ 11000] Loss Dis: 1.20, Loss Gen: 6.81 , 2[s]\n",
      "[3200/ 11000] Loss Dis: 0.98, Loss Gen: 10.92 , 2[s]\n",
      "\n",
      "[[0.00 0.96 0.95 0.26 0.99]\n",
      " [0.95 0.00 0.55 0.02 0.04]\n",
      " [0.97 0.99 0.00 0.36 0.06]\n",
      " [0.03 0.01 0.29 0.00 0.02]\n",
      " [0.99 0.10 0.07 0.17 0.00]]\n",
      "\n",
      "[3210/ 11000] Loss Dis: 1.17, Loss Gen: 6.03 , 3[s]\n",
      "[3220/ 11000] Loss Dis: 1.06, Loss Gen: 5.52 , 2[s]\n",
      "[3230/ 11000] Loss Dis: 0.89, Loss Gen: 13.41 , 3[s]\n",
      "[3240/ 11000] Loss Dis: 0.84, Loss Gen: 15.96 , 3[s]\n",
      "[3250/ 11000] Loss Dis: 0.96, Loss Gen: 18.17 , 3[s]\n",
      "[3260/ 11000] Loss Dis: 1.12, Loss Gen: 16.86 , 3[s]\n",
      "[3270/ 11000] Loss Dis: 1.03, Loss Gen: 6.51 , 3[s]\n",
      "[3280/ 11000] Loss Dis: 1.16, Loss Gen: 7.40 , 3[s]\n",
      "[3290/ 11000] Loss Dis: 0.85, Loss Gen: 18.07 , 2[s]\n",
      "[3300/ 11000] Loss Dis: 0.99, Loss Gen: 17.60 , 2[s]\n",
      "\n",
      "[[0.00 0.97 0.95 0.27 0.99]\n",
      " [0.95 0.00 0.51 0.02 0.03]\n",
      " [0.97 0.99 0.00 0.35 0.06]\n",
      " [0.03 0.01 0.29 0.00 0.02]\n",
      " [0.99 0.09 0.06 0.17 0.00]]\n",
      "\n",
      "[3310/ 11000] Loss Dis: 1.06, Loss Gen: 14.12 , 2[s]\n",
      "[3320/ 11000] Loss Dis: 1.27, Loss Gen: 5.56 , 2[s]\n",
      "[3330/ 11000] Loss Dis: 1.05, Loss Gen: 10.93 , 2[s]\n",
      "[3340/ 11000] Loss Dis: 0.92, Loss Gen: 16.84 , 2[s]\n",
      "[3350/ 11000] Loss Dis: 1.10, Loss Gen: 10.94 , 2[s]\n",
      "[3360/ 11000] Loss Dis: 0.92, Loss Gen: 16.24 , 2[s]\n",
      "[3370/ 11000] Loss Dis: 1.05, Loss Gen: 6.21 , 2[s]\n",
      "[3380/ 11000] Loss Dis: 0.58, Loss Gen: 27.61 , 2[s]\n",
      "[3390/ 11000] Loss Dis: 1.11, Loss Gen: 15.15 , 2[s]\n",
      "[3400/ 11000] Loss Dis: 1.04, Loss Gen: 9.43 , 2[s]\n",
      "\n",
      "[[0.00 0.97 0.94 0.30 0.99]\n",
      " [0.95 0.00 0.46 0.02 0.03]\n",
      " [0.97 0.99 0.00 0.34 0.06]\n",
      " [0.02 0.01 0.28 0.00 0.02]\n",
      " [0.99 0.09 0.06 0.17 0.00]]\n",
      "\n",
      "[3410/ 11000] Loss Dis: 1.12, Loss Gen: 23.86 , 2[s]\n",
      "[3420/ 11000] Loss Dis: 1.12, Loss Gen: 6.62 , 2[s]\n",
      "[3430/ 11000] Loss Dis: 1.02, Loss Gen: 15.36 , 2[s]\n",
      "[3440/ 11000] Loss Dis: 1.24, Loss Gen: 5.13 , 2[s]\n",
      "[3450/ 11000] Loss Dis: 1.01, Loss Gen: 18.92 , 2[s]\n",
      "[3460/ 11000] Loss Dis: 1.34, Loss Gen: 7.88 , 2[s]\n",
      "[3470/ 11000] Loss Dis: 1.04, Loss Gen: 13.64 , 2[s]\n",
      "[3480/ 11000] Loss Dis: 0.93, Loss Gen: 18.07 , 2[s]\n",
      "[3490/ 11000] Loss Dis: 0.97, Loss Gen: 14.39 , 2[s]\n",
      "[3500/ 11000] Loss Dis: 1.03, Loss Gen: 12.84 , 2[s]\n",
      "\n",
      "[[0.00 0.97 0.94 0.28 0.99]\n",
      " [0.95 0.00 0.42 0.02 0.03]\n",
      " [0.97 0.99 0.00 0.33 0.06]\n",
      " [0.02 0.01 0.27 0.00 0.02]\n",
      " [1.00 0.08 0.05 0.16 0.00]]\n",
      "\n",
      "[3510/ 11000] Loss Dis: 0.95, Loss Gen: 13.95 , 2[s]\n",
      "[3520/ 11000] Loss Dis: 0.87, Loss Gen: 18.33 , 2[s]\n",
      "[3530/ 11000] Loss Dis: 0.77, Loss Gen: 20.19 , 2[s]\n",
      "[3540/ 11000] Loss Dis: 0.83, Loss Gen: 21.81 , 2[s]\n",
      "[3550/ 11000] Loss Dis: 0.94, Loss Gen: 15.44 , 2[s]\n",
      "[3560/ 11000] Loss Dis: 0.94, Loss Gen: 14.94 , 2[s]\n",
      "[3570/ 11000] Loss Dis: 1.05, Loss Gen: 14.71 , 3[s]\n",
      "[3580/ 11000] Loss Dis: 1.25, Loss Gen: 13.56 , 2[s]\n",
      "[3590/ 11000] Loss Dis: 1.47, Loss Gen: 3.69 , 2[s]\n",
      "[3600/ 11000] Loss Dis: 1.05, Loss Gen: 12.68 , 2[s]\n",
      "\n",
      "[[0.00 0.97 0.94 0.27 0.99]\n",
      " [0.95 0.00 0.38 0.02 0.03]\n",
      " [0.97 0.99 0.00 0.32 0.07]\n",
      " [0.02 0.01 0.28 0.00 0.02]\n",
      " [1.00 0.08 0.05 0.16 0.00]]\n",
      "\n",
      "[3610/ 11000] Loss Dis: 1.02, Loss Gen: 16.62 , 2[s]\n",
      "[3620/ 11000] Loss Dis: 1.23, Loss Gen: 4.90 , 2[s]\n",
      "[3630/ 11000] Loss Dis: 0.94, Loss Gen: 16.36 , 2[s]\n",
      "[3640/ 11000] Loss Dis: 0.70, Loss Gen: 23.13 , 2[s]\n",
      "[3650/ 11000] Loss Dis: 0.88, Loss Gen: 16.57 , 2[s]\n",
      "[3660/ 11000] Loss Dis: 1.01, Loss Gen: 16.12 , 2[s]\n",
      "[3670/ 11000] Loss Dis: 1.15, Loss Gen: 5.91 , 2[s]\n",
      "[3680/ 11000] Loss Dis: 0.90, Loss Gen: 19.16 , 2[s]\n",
      "[3690/ 11000] Loss Dis: 1.04, Loss Gen: 7.23 , 2[s]\n",
      "[3700/ 11000] Loss Dis: 0.98, Loss Gen: 14.93 , 2[s]\n",
      "\n",
      "[[0.00 0.98 0.94 0.27 0.99]\n",
      " [0.95 0.00 0.33 0.02 0.02]\n",
      " [0.97 0.99 0.00 0.32 0.07]\n",
      " [0.02 0.01 0.28 0.00 0.01]\n",
      " [1.00 0.07 0.04 0.17 0.00]]\n",
      "\n",
      "[3710/ 11000] Loss Dis: 1.00, Loss Gen: 14.21 , 2[s]\n",
      "[3720/ 11000] Loss Dis: 0.93, Loss Gen: 18.50 , 2[s]\n",
      "[3730/ 11000] Loss Dis: 0.86, Loss Gen: 14.74 , 2[s]\n",
      "[3740/ 11000] Loss Dis: 1.08, Loss Gen: 6.17 , 2[s]\n",
      "[3750/ 11000] Loss Dis: 0.93, Loss Gen: 9.21 , 2[s]\n",
      "[3760/ 11000] Loss Dis: 0.98, Loss Gen: 14.19 , 2[s]\n",
      "[3770/ 11000] Loss Dis: 1.05, Loss Gen: 14.55 , 2[s]\n",
      "[3780/ 11000] Loss Dis: 1.09, Loss Gen: 14.46 , 2[s]\n",
      "[3790/ 11000] Loss Dis: 1.12, Loss Gen: 5.24 , 2[s]\n",
      "[3800/ 11000] Loss Dis: 0.93, Loss Gen: 15.17 , 2[s]\n",
      "\n",
      "[[0.00 0.98 0.94 0.29 0.99]\n",
      " [0.95 0.00 0.30 0.02 0.02]\n",
      " [0.97 0.99 0.00 0.33 0.07]\n",
      " [0.02 0.01 0.26 0.00 0.01]\n",
      " [1.00 0.07 0.04 0.17 0.00]]\n",
      "\n",
      "[3810/ 11000] Loss Dis: 1.18, Loss Gen: 5.12 , 2[s]\n",
      "[3820/ 11000] Loss Dis: 0.80, Loss Gen: 20.40 , 2[s]\n",
      "[3830/ 11000] Loss Dis: 1.17, Loss Gen: 12.26 , 2[s]\n",
      "[3840/ 11000] Loss Dis: 1.17, Loss Gen: 12.33 , 2[s]\n",
      "[3850/ 11000] Loss Dis: 0.90, Loss Gen: 15.40 , 2[s]\n",
      "[3860/ 11000] Loss Dis: 0.63, Loss Gen: 27.58 , 2[s]\n",
      "[3870/ 11000] Loss Dis: 1.01, Loss Gen: 7.49 , 2[s]\n",
      "[3880/ 11000] Loss Dis: 1.02, Loss Gen: 13.26 , 2[s]\n",
      "[3890/ 11000] Loss Dis: 1.24, Loss Gen: 6.01 , 2[s]\n",
      "[3900/ 11000] Loss Dis: 1.10, Loss Gen: 14.75 , 2[s]\n",
      "\n",
      "[[0.00 0.98 0.94 0.28 0.99]\n",
      " [0.96 0.00 0.29 0.01 0.02]\n",
      " [0.97 0.99 0.00 0.31 0.07]\n",
      " [0.01 0.01 0.27 0.00 0.01]\n",
      " [1.00 0.06 0.04 0.16 0.00]]\n",
      "\n",
      "[3910/ 11000] Loss Dis: 1.04, Loss Gen: 13.77 , 2[s]\n",
      "[3920/ 11000] Loss Dis: 1.06, Loss Gen: 12.91 , 2[s]\n",
      "[3930/ 11000] Loss Dis: 0.67, Loss Gen: 29.94 , 2[s]\n",
      "[3940/ 11000] Loss Dis: 0.90, Loss Gen: 15.80 , 2[s]\n",
      "[3950/ 11000] Loss Dis: 1.12, Loss Gen: 13.66 , 2[s]\n",
      "[3960/ 11000] Loss Dis: 0.83, Loss Gen: 7.73 , 2[s]\n",
      "[3970/ 11000] Loss Dis: 1.14, Loss Gen: 13.10 , 2[s]\n",
      "[3980/ 11000] Loss Dis: 0.91, Loss Gen: 21.28 , 2[s]\n",
      "[3990/ 11000] Loss Dis: 1.05, Loss Gen: 12.77 , 2[s]\n",
      "[4000/ 11000] Loss Dis: 1.06, Loss Gen: 6.47 , 2[s]\n",
      "\n",
      "[[0.00 0.98 0.94 0.30 0.99]\n",
      " [0.96 0.00 0.29 0.01 0.02]\n",
      " [0.97 0.99 0.00 0.31 0.07]\n",
      " [0.01 0.01 0.27 0.00 0.01]\n",
      " [1.00 0.06 0.03 0.16 0.00]]\n",
      "\n",
      "[4010/ 11000] Loss Dis: 0.92, Loss Gen: 16.44 , 2[s]\n",
      "[4020/ 11000] Loss Dis: 0.84, Loss Gen: 19.95 , 2[s]\n",
      "[4030/ 11000] Loss Dis: 0.98, Loss Gen: 14.20 , 2[s]\n",
      "[4040/ 11000] Loss Dis: 1.15, Loss Gen: 18.05 , 2[s]\n",
      "[4050/ 11000] Loss Dis: 0.91, Loss Gen: 14.49 , 2[s]\n",
      "[4060/ 11000] Loss Dis: 0.94, Loss Gen: 15.61 , 2[s]\n",
      "[4070/ 11000] Loss Dis: 0.86, Loss Gen: 25.51 , 2[s]\n",
      "[4080/ 11000] Loss Dis: 0.96, Loss Gen: 11.94 , 3[s]\n",
      "[4090/ 11000] Loss Dis: 1.49, Loss Gen: 5.69 , 2[s]\n",
      "[4100/ 11000] Loss Dis: 1.15, Loss Gen: 12.70 , 2[s]\n",
      "\n",
      "[[0.00 0.98 0.94 0.30 0.99]\n",
      " [0.96 0.00 0.28 0.01 0.02]\n",
      " [0.97 0.99 0.00 0.30 0.07]\n",
      " [0.01 0.01 0.28 0.00 0.01]\n",
      " [1.00 0.05 0.03 0.17 0.00]]\n",
      "\n",
      "[4110/ 11000] Loss Dis: 1.12, Loss Gen: 12.90 , 2[s]\n",
      "[4120/ 11000] Loss Dis: 1.25, Loss Gen: 13.70 , 2[s]\n",
      "[4130/ 11000] Loss Dis: 1.30, Loss Gen: 4.78 , 2[s]\n",
      "[4140/ 11000] Loss Dis: 1.24, Loss Gen: 5.47 , 2[s]\n",
      "[4150/ 11000] Loss Dis: 1.08, Loss Gen: 12.88 , 2[s]\n",
      "[4160/ 11000] Loss Dis: 1.10, Loss Gen: 13.45 , 2[s]\n",
      "[4170/ 11000] Loss Dis: 1.20, Loss Gen: 4.49 , 2[s]\n",
      "[4180/ 11000] Loss Dis: 1.19, Loss Gen: 4.45 , 2[s]\n",
      "[4190/ 11000] Loss Dis: 0.99, Loss Gen: 14.23 , 2[s]\n",
      "[4200/ 11000] Loss Dis: 1.06, Loss Gen: 5.73 , 3[s]\n",
      "\n",
      "[[0.00 0.98 0.94 0.29 0.99]\n",
      " [0.96 0.00 0.29 0.01 0.02]\n",
      " [0.97 0.99 0.00 0.28 0.06]\n",
      " [0.01 0.01 0.31 0.00 0.01]\n",
      " [1.00 0.05 0.03 0.16 0.00]]\n",
      "\n",
      "[4210/ 11000] Loss Dis: 1.07, Loss Gen: 13.76 , 2[s]\n",
      "[4220/ 11000] Loss Dis: 1.07, Loss Gen: 13.66 , 2[s]\n",
      "[4230/ 11000] Loss Dis: 1.09, Loss Gen: 7.11 , 2[s]\n",
      "[4240/ 11000] Loss Dis: 1.14, Loss Gen: 14.65 , 2[s]\n",
      "[4250/ 11000] Loss Dis: 1.25, Loss Gen: 7.01 , 2[s]\n",
      "[4260/ 11000] Loss Dis: 0.96, Loss Gen: 13.57 , 2[s]\n",
      "[4270/ 11000] Loss Dis: 1.13, Loss Gen: 13.40 , 2[s]\n",
      "[4280/ 11000] Loss Dis: 0.94, Loss Gen: 17.36 , 2[s]\n",
      "[4290/ 11000] Loss Dis: 1.31, Loss Gen: 7.91 , 2[s]\n",
      "[4300/ 11000] Loss Dis: 1.07, Loss Gen: 12.88 , 2[s]\n",
      "\n",
      "[[0.00 0.98 0.94 0.30 0.99]\n",
      " [0.96 0.00 0.34 0.01 0.02]\n",
      " [0.97 0.99 0.00 0.26 0.06]\n",
      " [0.01 0.01 0.34 0.00 0.01]\n",
      " [1.00 0.04 0.03 0.15 0.00]]\n",
      "\n",
      "[4310/ 11000] Loss Dis: 1.18, Loss Gen: 12.97 , 2[s]\n",
      "[4320/ 11000] Loss Dis: 1.18, Loss Gen: 12.44 , 3[s]\n",
      "[4330/ 11000] Loss Dis: 1.09, Loss Gen: 13.52 , 2[s]\n",
      "[4340/ 11000] Loss Dis: 0.99, Loss Gen: 14.05 , 2[s]\n",
      "[4350/ 11000] Loss Dis: 1.00, Loss Gen: 15.20 , 3[s]\n",
      "[4360/ 11000] Loss Dis: 1.26, Loss Gen: 12.07 , 2[s]\n",
      "[4370/ 11000] Loss Dis: 1.22, Loss Gen: 13.06 , 2[s]\n",
      "[4380/ 11000] Loss Dis: 1.19, Loss Gen: 5.23 , 2[s]\n",
      "[4390/ 11000] Loss Dis: 1.06, Loss Gen: 11.56 , 2[s]\n",
      "[4400/ 11000] Loss Dis: 1.07, Loss Gen: 12.60 , 2[s]\n",
      "\n",
      "[[0.00 0.98 0.93 0.30 0.99]\n",
      " [0.95 0.00 0.37 0.01 0.02]\n",
      " [0.97 0.99 0.00 0.24 0.05]\n",
      " [0.01 0.00 0.34 0.00 0.01]\n",
      " [1.00 0.04 0.02 0.15 0.00]]\n",
      "\n",
      "[4410/ 11000] Loss Dis: 1.10, Loss Gen: 12.91 , 2[s]\n",
      "[4420/ 11000] Loss Dis: 1.02, Loss Gen: 9.06 , 3[s]\n",
      "[4430/ 11000] Loss Dis: 0.90, Loss Gen: 23.45 , 3[s]\n",
      "[4440/ 11000] Loss Dis: 1.20, Loss Gen: 5.83 , 3[s]\n",
      "[4450/ 11000] Loss Dis: 1.20, Loss Gen: 12.45 , 2[s]\n",
      "[4460/ 11000] Loss Dis: 1.23, Loss Gen: 4.24 , 3[s]\n",
      "[4470/ 11000] Loss Dis: 1.23, Loss Gen: 4.64 , 3[s]\n",
      "[4480/ 11000] Loss Dis: 1.05, Loss Gen: 13.46 , 3[s]\n",
      "[4490/ 11000] Loss Dis: 0.86, Loss Gen: 20.24 , 3[s]\n",
      "[4500/ 11000] Loss Dis: 1.29, Loss Gen: 16.99 , 3[s]\n",
      "\n",
      "[[0.00 0.98 0.93 0.31 0.99]\n",
      " [0.95 0.00 0.41 0.01 0.01]\n",
      " [0.96 0.99 0.00 0.22 0.06]\n",
      " [0.01 0.00 0.38 0.00 0.01]\n",
      " [1.00 0.04 0.03 0.16 0.00]]\n",
      "\n",
      "[4510/ 11000] Loss Dis: 1.15, Loss Gen: 13.13 , 3[s]\n",
      "[4520/ 11000] Loss Dis: 1.10, Loss Gen: 12.66 , 3[s]\n",
      "[4530/ 11000] Loss Dis: 1.19, Loss Gen: 13.12 , 3[s]\n",
      "[4540/ 11000] Loss Dis: 1.09, Loss Gen: 13.28 , 2[s]\n",
      "[4550/ 11000] Loss Dis: 1.13, Loss Gen: 14.42 , 2[s]\n",
      "[4560/ 11000] Loss Dis: 1.05, Loss Gen: 14.97 , 2[s]\n",
      "[4570/ 11000] Loss Dis: 1.03, Loss Gen: 13.37 , 3[s]\n",
      "[4580/ 11000] Loss Dis: 1.23, Loss Gen: 6.25 , 2[s]\n",
      "[4590/ 11000] Loss Dis: 1.16, Loss Gen: 5.87 , 2[s]\n",
      "[4600/ 11000] Loss Dis: 1.19, Loss Gen: 5.42 , 2[s]\n",
      "\n",
      "[[0.00 0.98 0.93 0.33 0.99]\n",
      " [0.96 0.00 0.45 0.01 0.01]\n",
      " [0.96 0.99 0.00 0.21 0.06]\n",
      " [0.01 0.00 0.40 0.00 0.01]\n",
      " [1.00 0.03 0.03 0.16 0.00]]\n",
      "\n",
      "[4610/ 11000] Loss Dis: 1.02, Loss Gen: 7.07 , 2[s]\n",
      "[4620/ 11000] Loss Dis: 1.18, Loss Gen: 14.45 , 2[s]\n",
      "[4630/ 11000] Loss Dis: 1.21, Loss Gen: 13.51 , 2[s]\n",
      "[4640/ 11000] Loss Dis: 1.03, Loss Gen: 16.07 , 2[s]\n",
      "[4650/ 11000] Loss Dis: 1.15, Loss Gen: 13.82 , 2[s]\n",
      "[4660/ 11000] Loss Dis: 1.11, Loss Gen: 13.39 , 2[s]\n",
      "[4670/ 11000] Loss Dis: 0.85, Loss Gen: 22.26 , 2[s]\n",
      "[4680/ 11000] Loss Dis: 1.23, Loss Gen: 5.68 , 2[s]\n",
      "[4690/ 11000] Loss Dis: 1.00, Loss Gen: 14.78 , 2[s]\n",
      "[4700/ 11000] Loss Dis: 1.28, Loss Gen: 13.17 , 2[s]\n",
      "\n",
      "[[0.00 0.98 0.94 0.34 0.99]\n",
      " [0.96 0.00 0.44 0.01 0.02]\n",
      " [0.97 0.99 0.00 0.20 0.06]\n",
      " [0.01 0.00 0.45 0.00 0.01]\n",
      " [1.00 0.03 0.02 0.15 0.00]]\n",
      "\n",
      "[4710/ 11000] Loss Dis: 1.39, Loss Gen: 5.19 , 2[s]\n",
      "[4720/ 11000] Loss Dis: 1.12, Loss Gen: 12.97 , 2[s]\n",
      "[4730/ 11000] Loss Dis: 1.10, Loss Gen: 12.94 , 2[s]\n",
      "[4740/ 11000] Loss Dis: 1.11, Loss Gen: 13.44 , 2[s]\n",
      "[4750/ 11000] Loss Dis: 0.97, Loss Gen: 13.09 , 2[s]\n",
      "[4760/ 11000] Loss Dis: 1.17, Loss Gen: 12.74 , 2[s]\n",
      "[4770/ 11000] Loss Dis: 1.11, Loss Gen: 13.40 , 2[s]\n",
      "[4780/ 11000] Loss Dis: 1.11, Loss Gen: 13.06 , 2[s]\n",
      "[4790/ 11000] Loss Dis: 1.09, Loss Gen: 13.20 , 2[s]\n",
      "[4800/ 11000] Loss Dis: 1.06, Loss Gen: 13.20 , 2[s]\n",
      "\n",
      "[[0.00 0.98 0.94 0.34 0.99]\n",
      " [0.96 0.00 0.45 0.01 0.02]\n",
      " [0.97 0.99 0.00 0.19 0.06]\n",
      " [0.01 0.00 0.49 0.00 0.01]\n",
      " [1.00 0.03 0.02 0.16 0.00]]\n",
      "\n",
      "[4810/ 11000] Loss Dis: 0.99, Loss Gen: 14.10 , 2[s]\n",
      "[4820/ 11000] Loss Dis: 0.92, Loss Gen: 20.68 , 2[s]\n",
      "[4830/ 11000] Loss Dis: 0.97, Loss Gen: 14.97 , 2[s]\n",
      "[4840/ 11000] Loss Dis: 1.08, Loss Gen: 14.45 , 2[s]\n",
      "[4850/ 11000] Loss Dis: 1.14, Loss Gen: 5.05 , 2[s]\n",
      "[4860/ 11000] Loss Dis: 1.26, Loss Gen: 5.49 , 2[s]\n",
      "[4870/ 11000] Loss Dis: 1.02, Loss Gen: 12.65 , 2[s]\n",
      "[4880/ 11000] Loss Dis: 0.98, Loss Gen: 13.55 , 2[s]\n",
      "[4890/ 11000] Loss Dis: 1.07, Loss Gen: 15.03 , 2[s]\n",
      "[4900/ 11000] Loss Dis: 1.06, Loss Gen: 12.42 , 2[s]\n",
      "\n",
      "[[0.00 0.98 0.94 0.37 0.99]\n",
      " [0.96 0.00 0.47 0.01 0.02]\n",
      " [0.97 0.99 0.00 0.17 0.06]\n",
      " [0.01 0.00 0.50 0.00 0.01]\n",
      " [1.00 0.03 0.03 0.18 0.00]]\n",
      "\n",
      "[4910/ 11000] Loss Dis: 1.22, Loss Gen: 9.03 , 2[s]\n",
      "[4920/ 11000] Loss Dis: 1.14, Loss Gen: 13.17 , 2[s]\n",
      "[4930/ 11000] Loss Dis: 0.92, Loss Gen: 15.69 , 2[s]\n",
      "[4940/ 11000] Loss Dis: 1.03, Loss Gen: 12.20 , 3[s]\n",
      "[4950/ 11000] Loss Dis: 1.13, Loss Gen: 14.02 , 3[s]\n",
      "[4960/ 11000] Loss Dis: 1.02, Loss Gen: 13.73 , 3[s]\n",
      "[4970/ 11000] Loss Dis: 1.27, Loss Gen: 13.57 , 3[s]\n",
      "[4980/ 11000] Loss Dis: 1.14, Loss Gen: 5.61 , 3[s]\n",
      "[4990/ 11000] Loss Dis: 1.11, Loss Gen: 11.10 , 3[s]\n",
      "[5000/ 11000] Loss Dis: 1.12, Loss Gen: 4.95 , 3[s]\n",
      "\n",
      "[[0.00 0.98 0.95 0.39 0.99]\n",
      " [0.96 0.00 0.49 0.01 0.03]\n",
      " [0.97 0.99 0.00 0.16 0.07]\n",
      " [0.01 0.00 0.54 0.00 0.00]\n",
      " [1.00 0.02 0.02 0.16 0.00]]\n",
      "\n",
      "[5010/ 11000] Loss Dis: 1.11, Loss Gen: 4.56 , 3[s]\n",
      "[5020/ 11000] Loss Dis: 0.78, Loss Gen: 25.71 , 3[s]\n",
      "[5030/ 11000] Loss Dis: 0.87, Loss Gen: 20.04 , 3[s]\n",
      "[5040/ 11000] Loss Dis: 1.12, Loss Gen: 6.79 , 3[s]\n",
      "[5050/ 11000] Loss Dis: 0.99, Loss Gen: 14.17 , 3[s]\n",
      "[5060/ 11000] Loss Dis: 1.28, Loss Gen: 14.81 , 3[s]\n",
      "[5070/ 11000] Loss Dis: 1.14, Loss Gen: 13.02 , 3[s]\n",
      "[5080/ 11000] Loss Dis: 1.15, Loss Gen: 14.88 , 3[s]\n",
      "[5090/ 11000] Loss Dis: 0.88, Loss Gen: 20.87 , 3[s]\n",
      "[5100/ 11000] Loss Dis: 1.12, Loss Gen: 5.40 , 3[s]\n",
      "\n",
      "[[0.00 0.98 0.90 0.27 0.99]\n",
      " [0.95 0.00 0.41 0.01 0.03]\n",
      " [0.97 0.99 0.00 0.13 0.06]\n",
      " [0.01 0.00 0.32 0.00 0.00]\n",
      " [1.00 0.02 0.02 0.14 0.00]]\n",
      "\n",
      "[5110/ 11000] Loss Dis: 1.00, Loss Gen: 11.22 , 3[s]\n",
      "[5120/ 11000] Loss Dis: 1.19, Loss Gen: 13.91 , 3[s]\n",
      "[5130/ 11000] Loss Dis: 1.23, Loss Gen: 13.54 , 3[s]\n",
      "[5140/ 11000] Loss Dis: 1.27, Loss Gen: 5.00 , 3[s]\n",
      "[5150/ 11000] Loss Dis: 0.94, Loss Gen: 18.85 , 3[s]\n",
      "[5160/ 11000] Loss Dis: 1.08, Loss Gen: 12.91 , 3[s]\n",
      "[5170/ 11000] Loss Dis: 0.97, Loss Gen: 13.65 , 3[s]\n",
      "[5180/ 11000] Loss Dis: 0.90, Loss Gen: 12.19 , 3[s]\n",
      "[5190/ 11000] Loss Dis: 0.91, Loss Gen: 14.84 , 3[s]\n",
      "[5200/ 11000] Loss Dis: 0.79, Loss Gen: 21.04 , 3[s]\n",
      "\n",
      "[[0.00 0.97 0.36 0.21 0.98]\n",
      " [0.84 0.00 0.30 0.01 0.02]\n",
      " [0.96 0.99 0.00 0.10 0.05]\n",
      " [0.01 0.00 0.21 0.00 0.00]\n",
      " [1.00 0.02 0.02 0.14 0.00]]\n",
      "\n",
      "[5210/ 11000] Loss Dis: 1.11, Loss Gen: 5.29 , 3[s]\n",
      "[5220/ 11000] Loss Dis: 1.09, Loss Gen: 13.99 , 3[s]\n",
      "[5230/ 11000] Loss Dis: 1.06, Loss Gen: 13.29 , 3[s]\n",
      "[5240/ 11000] Loss Dis: 0.91, Loss Gen: 20.17 , 3[s]\n",
      "[5250/ 11000] Loss Dis: 0.98, Loss Gen: 12.80 , 3[s]\n",
      "[5260/ 11000] Loss Dis: 1.12, Loss Gen: 12.60 , 3[s]\n",
      "[5270/ 11000] Loss Dis: 0.88, Loss Gen: 20.94 , 3[s]\n",
      "[5280/ 11000] Loss Dis: 1.02, Loss Gen: 13.48 , 3[s]\n",
      "[5290/ 11000] Loss Dis: 0.86, Loss Gen: 20.68 , 3[s]\n",
      "[5300/ 11000] Loss Dis: 1.00, Loss Gen: 21.65 , 3[s]\n",
      "\n",
      "[[0.00 0.94 0.11 0.18 0.89]\n",
      " [0.42 0.00 0.35 0.01 0.02]\n",
      " [0.96 0.99 0.00 0.09 0.05]\n",
      " [0.01 0.00 0.29 0.00 0.00]\n",
      " [1.00 0.02 0.02 0.15 0.00]]\n",
      "\n",
      "[5310/ 11000] Loss Dis: 1.17, Loss Gen: 11.90 , 3[s]\n",
      "[5320/ 11000] Loss Dis: 1.04, Loss Gen: 11.93 , 3[s]\n",
      "[5330/ 11000] Loss Dis: 0.84, Loss Gen: 19.29 , 3[s]\n",
      "[5340/ 11000] Loss Dis: 0.66, Loss Gen: 26.07 , 3[s]\n",
      "[5350/ 11000] Loss Dis: 0.84, Loss Gen: 20.03 , 3[s]\n",
      "[5360/ 11000] Loss Dis: 0.71, Loss Gen: 24.61 , 3[s]\n",
      "[5370/ 11000] Loss Dis: 0.66, Loss Gen: 24.24 , 3[s]\n",
      "[5380/ 11000] Loss Dis: 0.84, Loss Gen: 19.08 , 3[s]\n",
      "[5390/ 11000] Loss Dis: 0.93, Loss Gen: 20.05 , 3[s]\n",
      "[5400/ 11000] Loss Dis: 0.62, Loss Gen: 26.56 , 3[s]\n",
      "\n",
      "[[0.00 0.89 0.04 0.12 0.26]\n",
      " [0.23 0.00 0.45 0.01 0.01]\n",
      " [0.95 0.99 0.00 0.06 0.05]\n",
      " [0.01 0.00 0.52 0.00 0.00]\n",
      " [1.00 0.02 0.07 0.17 0.00]]\n",
      "\n",
      "[5410/ 11000] Loss Dis: 0.61, Loss Gen: 24.73 , 3[s]\n",
      "[5420/ 11000] Loss Dis: 0.78, Loss Gen: 21.37 , 3[s]\n",
      "[5430/ 11000] Loss Dis: 0.87, Loss Gen: 19.75 , 3[s]\n",
      "[5440/ 11000] Loss Dis: 0.65, Loss Gen: 27.04 , 3[s]\n",
      "[5450/ 11000] Loss Dis: 0.59, Loss Gen: 27.47 , 3[s]\n",
      "[5460/ 11000] Loss Dis: 0.68, Loss Gen: 26.44 , 3[s]\n",
      "[5470/ 11000] Loss Dis: 0.49, Loss Gen: 32.89 , 3[s]\n",
      "[5480/ 11000] Loss Dis: 0.70, Loss Gen: 21.09 , 3[s]\n",
      "[5490/ 11000] Loss Dis: 0.34, Loss Gen: 33.64 , 3[s]\n",
      "[5500/ 11000] Loss Dis: 0.60, Loss Gen: 38.03 , 3[s]\n",
      "\n",
      "[[0.00 0.86 0.03 0.07 0.19]\n",
      " [0.18 0.00 0.31 0.01 0.01]\n",
      " [0.92 0.99 0.00 0.04 0.06]\n",
      " [0.01 0.00 0.76 0.00 0.00]\n",
      " [1.00 0.01 0.23 0.24 0.00]]\n",
      "\n",
      "[5510/ 11000] Loss Dis: 0.69, Loss Gen: 21.40 , 3[s]\n",
      "[5520/ 11000] Loss Dis: 0.64, Loss Gen: 22.21 , 3[s]\n",
      "[5530/ 11000] Loss Dis: 0.57, Loss Gen: 28.67 , 3[s]\n",
      "[5540/ 11000] Loss Dis: 0.66, Loss Gen: 22.05 , 3[s]\n",
      "[5550/ 11000] Loss Dis: 0.65, Loss Gen: 22.27 , 3[s]\n",
      "[5560/ 11000] Loss Dis: 0.57, Loss Gen: 24.73 , 3[s]\n",
      "[5570/ 11000] Loss Dis: 0.85, Loss Gen: 18.60 , 3[s]\n",
      "[5580/ 11000] Loss Dis: 0.98, Loss Gen: 13.06 , 3[s]\n",
      "[5590/ 11000] Loss Dis: 0.87, Loss Gen: 18.78 , 3[s]\n",
      "[5600/ 11000] Loss Dis: 0.69, Loss Gen: 17.82 , 3[s]\n",
      "\n",
      "[[0.00 0.87 0.03 0.04 0.18]\n",
      " [0.14 0.00 0.22 0.01 0.01]\n",
      " [0.92 0.99 0.00 0.03 0.05]\n",
      " [0.01 0.00 0.85 0.00 0.00]\n",
      " [1.00 0.01 0.49 0.25 0.00]]\n",
      "\n",
      "[5610/ 11000] Loss Dis: 0.65, Loss Gen: 20.99 , 3[s]\n",
      "[5620/ 11000] Loss Dis: 0.61, Loss Gen: 22.95 , 3[s]\n",
      "[5630/ 11000] Loss Dis: 0.92, Loss Gen: 13.75 , 3[s]\n",
      "[5640/ 11000] Loss Dis: 0.65, Loss Gen: 20.77 , 3[s]\n",
      "[5650/ 11000] Loss Dis: 0.61, Loss Gen: 23.21 , 3[s]\n",
      "[5660/ 11000] Loss Dis: 0.64, Loss Gen: 20.44 , 3[s]\n",
      "[5670/ 11000] Loss Dis: 0.73, Loss Gen: 23.25 , 3[s]\n",
      "[5680/ 11000] Loss Dis: 0.73, Loss Gen: 19.90 , 3[s]\n",
      "[5690/ 11000] Loss Dis: 0.87, Loss Gen: 15.19 , 3[s]\n",
      "[5700/ 11000] Loss Dis: 0.76, Loss Gen: 22.78 , 3[s]\n",
      "\n",
      "[[0.00 0.90 0.02 0.03 0.17]\n",
      " [0.11 0.00 0.19 0.01 0.01]\n",
      " [0.92 0.99 0.00 0.02 0.03]\n",
      " [0.01 0.00 0.87 0.00 0.00]\n",
      " [1.00 0.01 0.76 0.29 0.00]]\n",
      "\n",
      "[5710/ 11000] Loss Dis: 0.80, Loss Gen: 17.02 , 3[s]\n",
      "[5720/ 11000] Loss Dis: 0.50, Loss Gen: 27.81 , 3[s]\n",
      "[5730/ 11000] Loss Dis: 0.62, Loss Gen: 22.35 , 3[s]\n",
      "[5740/ 11000] Loss Dis: 0.57, Loss Gen: 21.43 , 3[s]\n",
      "[5750/ 11000] Loss Dis: 0.89, Loss Gen: 13.89 , 3[s]\n",
      "[5760/ 11000] Loss Dis: 0.72, Loss Gen: 24.70 , 3[s]\n",
      "[5770/ 11000] Loss Dis: 0.43, Loss Gen: 35.27 , 3[s]\n",
      "[5780/ 11000] Loss Dis: 0.59, Loss Gen: 21.23 , 3[s]\n",
      "[5790/ 11000] Loss Dis: 0.51, Loss Gen: 25.97 , 3[s]\n",
      "[5800/ 11000] Loss Dis: 0.57, Loss Gen: 23.13 , 3[s]\n",
      "\n",
      "[[0.00 0.91 0.02 0.02 0.14]\n",
      " [0.09 0.00 0.15 0.00 0.01]\n",
      " [0.93 0.99 0.00 0.02 0.02]\n",
      " [0.00 0.00 0.92 0.00 0.01]\n",
      " [1.00 0.01 0.84 0.29 0.00]]\n",
      "\n",
      "[5810/ 11000] Loss Dis: 0.65, Loss Gen: 22.49 , 3[s]\n",
      "[5820/ 11000] Loss Dis: 0.61, Loss Gen: 21.74 , 3[s]\n",
      "[5830/ 11000] Loss Dis: 0.50, Loss Gen: 31.06 , 3[s]\n",
      "[5840/ 11000] Loss Dis: 0.64, Loss Gen: 21.13 , 3[s]\n",
      "[5850/ 11000] Loss Dis: 0.63, Loss Gen: 21.33 , 3[s]\n",
      "[5860/ 11000] Loss Dis: 0.59, Loss Gen: 22.05 , 3[s]\n",
      "[5870/ 11000] Loss Dis: 0.61, Loss Gen: 23.16 , 3[s]\n",
      "[5880/ 11000] Loss Dis: 0.54, Loss Gen: 23.61 , 3[s]\n",
      "[5890/ 11000] Loss Dis: 0.55, Loss Gen: 24.41 , 3[s]\n",
      "[5900/ 11000] Loss Dis: 0.66, Loss Gen: 25.13 , 3[s]\n",
      "\n",
      "[[0.00 0.93 0.02 0.02 0.16]\n",
      " [0.07 0.00 0.13 0.00 0.01]\n",
      " [0.95 0.99 0.00 0.01 0.02]\n",
      " [0.00 0.00 0.95 0.00 0.01]\n",
      " [1.00 0.01 0.87 0.35 0.00]]\n",
      "\n",
      "[5910/ 11000] Loss Dis: 0.72, Loss Gen: 19.38 , 3[s]\n",
      "[5920/ 11000] Loss Dis: 0.56, Loss Gen: 21.43 , 3[s]\n",
      "[5930/ 11000] Loss Dis: 0.56, Loss Gen: 22.20 , 3[s]\n",
      "[5940/ 11000] Loss Dis: 0.54, Loss Gen: 25.79 , 3[s]\n",
      "[5950/ 11000] Loss Dis: 0.55, Loss Gen: 23.69 , 3[s]\n",
      "[5960/ 11000] Loss Dis: 0.68, Loss Gen: 24.72 , 3[s]\n",
      "[5970/ 11000] Loss Dis: 0.87, Loss Gen: 19.40 , 3[s]\n",
      "[5980/ 11000] Loss Dis: 0.87, Loss Gen: 15.66 , 3[s]\n",
      "[5990/ 11000] Loss Dis: 0.68, Loss Gen: 18.21 , 3[s]\n",
      "[6000/ 11000] Loss Dis: 0.63, Loss Gen: 18.14 , 3[s]\n",
      "\n",
      "[[0.00 0.94 0.02 0.02 0.16]\n",
      " [0.06 0.00 0.11 0.00 0.01]\n",
      " [0.95 0.99 0.00 0.01 0.01]\n",
      " [0.00 0.00 0.95 0.00 0.02]\n",
      " [1.00 0.01 0.89 0.33 0.00]]\n",
      "\n",
      "[6010/ 11000] Loss Dis: 0.60, Loss Gen: 19.16 , 3[s]\n",
      "[6020/ 11000] Loss Dis: 0.35, Loss Gen: 28.31 , 3[s]\n",
      "[6030/ 11000] Loss Dis: 0.53, Loss Gen: 23.84 , 3[s]\n",
      "[6040/ 11000] Loss Dis: 0.63, Loss Gen: 23.49 , 3[s]\n",
      "[6050/ 11000] Loss Dis: 0.64, Loss Gen: 20.03 , 3[s]\n",
      "[6060/ 11000] Loss Dis: 0.85, Loss Gen: 19.89 , 3[s]\n",
      "[6070/ 11000] Loss Dis: 0.67, Loss Gen: 18.09 , 3[s]\n",
      "[6080/ 11000] Loss Dis: 0.61, Loss Gen: 21.39 , 3[s]\n",
      "[6090/ 11000] Loss Dis: 0.51, Loss Gen: 20.90 , 3[s]\n",
      "[6100/ 11000] Loss Dis: 0.61, Loss Gen: 22.73 , 3[s]\n",
      "\n",
      "[[0.00 0.95 0.02 0.01 0.15]\n",
      " [0.05 0.00 0.09 0.00 0.00]\n",
      " [0.95 0.99 0.00 0.01 0.01]\n",
      " [0.00 0.00 0.95 0.00 0.13]\n",
      " [1.00 0.01 0.88 0.27 0.00]]\n",
      "\n",
      "[6110/ 11000] Loss Dis: 0.52, Loss Gen: 23.52 , 3[s]\n",
      "[6120/ 11000] Loss Dis: 0.81, Loss Gen: 22.50 , 3[s]\n",
      "[6130/ 11000] Loss Dis: 0.69, Loss Gen: 21.67 , 3[s]\n",
      "[6140/ 11000] Loss Dis: 0.89, Loss Gen: 15.24 , 3[s]\n",
      "[6150/ 11000] Loss Dis: 0.50, Loss Gen: 26.41 , 3[s]\n",
      "[6160/ 11000] Loss Dis: 0.64, Loss Gen: 21.23 , 3[s]\n",
      "[6170/ 11000] Loss Dis: 0.79, Loss Gen: 14.81 , 3[s]\n",
      "[6180/ 11000] Loss Dis: 0.80, Loss Gen: 26.89 , 3[s]\n",
      "[6190/ 11000] Loss Dis: 0.65, Loss Gen: 22.09 , 3[s]\n",
      "[6200/ 11000] Loss Dis: 0.80, Loss Gen: 17.72 , 3[s]\n",
      "\n",
      "[[0.00 0.96 0.02 0.01 0.14]\n",
      " [0.05 0.00 0.07 0.00 0.00]\n",
      " [0.95 0.99 0.00 0.01 0.02]\n",
      " [0.00 0.00 0.95 0.00 0.53]\n",
      " [1.00 0.01 0.87 0.08 0.00]]\n",
      "\n",
      "[6210/ 11000] Loss Dis: 0.59, Loss Gen: 23.16 , 3[s]\n",
      "[6220/ 11000] Loss Dis: 0.60, Loss Gen: 23.55 , 3[s]\n",
      "[6230/ 11000] Loss Dis: 0.55, Loss Gen: 24.26 , 3[s]\n",
      "[6240/ 11000] Loss Dis: 0.53, Loss Gen: 23.29 , 3[s]\n",
      "[6250/ 11000] Loss Dis: 0.66, Loss Gen: 22.62 , 3[s]\n",
      "[6260/ 11000] Loss Dis: 1.06, Loss Gen: 19.47 , 3[s]\n",
      "[6270/ 11000] Loss Dis: 0.83, Loss Gen: 16.03 , 3[s]\n",
      "[6280/ 11000] Loss Dis: 0.52, Loss Gen: 24.99 , 3[s]\n",
      "[6290/ 11000] Loss Dis: 0.64, Loss Gen: 18.43 , 3[s]\n",
      "[6300/ 11000] Loss Dis: 0.62, Loss Gen: 19.42 , 3[s]\n",
      "\n",
      "[[0.00 0.97 0.02 0.01 0.14]\n",
      " [0.05 0.00 0.07 0.00 0.00]\n",
      " [0.96 0.99 0.00 0.01 0.02]\n",
      " [0.00 0.00 0.96 0.00 0.83]\n",
      " [1.00 0.01 0.88 0.03 0.00]]\n",
      "\n",
      "[6310/ 11000] Loss Dis: 0.57, Loss Gen: 20.75 , 3[s]\n",
      "[6320/ 11000] Loss Dis: 0.38, Loss Gen: 33.76 , 3[s]\n",
      "[6330/ 11000] Loss Dis: 0.52, Loss Gen: 23.30 , 3[s]\n",
      "[6340/ 11000] Loss Dis: 0.73, Loss Gen: 17.80 , 3[s]\n",
      "[6350/ 11000] Loss Dis: 0.51, Loss Gen: 25.91 , 3[s]\n",
      "[6360/ 11000] Loss Dis: 0.37, Loss Gen: 32.50 , 3[s]\n",
      "[6370/ 11000] Loss Dis: 0.50, Loss Gen: 25.25 , 3[s]\n",
      "[6380/ 11000] Loss Dis: 0.51, Loss Gen: 25.40 , 3[s]\n",
      "[6390/ 11000] Loss Dis: 0.55, Loss Gen: 25.71 , 3[s]\n",
      "[6400/ 11000] Loss Dis: 1.27, Loss Gen: 21.50 , 3[s]\n",
      "\n",
      "[[0.00 0.97 0.02 0.01 0.12]\n",
      " [0.04 0.00 0.06 0.00 0.00]\n",
      " [0.96 0.99 0.00 0.01 0.03]\n",
      " [0.00 0.00 0.96 0.00 0.91]\n",
      " [1.00 0.01 0.88 0.02 0.00]]\n",
      "\n",
      "[6410/ 11000] Loss Dis: 0.82, Loss Gen: 20.28 , 3[s]\n",
      "[6420/ 11000] Loss Dis: 0.62, Loss Gen: 19.66 , 3[s]\n",
      "[6430/ 11000] Loss Dis: 0.62, Loss Gen: 25.13 , 4[s]\n",
      "[6440/ 11000] Loss Dis: 0.51, Loss Gen: 22.18 , 3[s]\n",
      "[6450/ 11000] Loss Dis: 0.48, Loss Gen: 23.37 , 3[s]\n",
      "[6460/ 11000] Loss Dis: 0.47, Loss Gen: 24.23 , 3[s]\n",
      "[6470/ 11000] Loss Dis: 0.45, Loss Gen: 24.95 , 4[s]\n",
      "[6480/ 11000] Loss Dis: 0.56, Loss Gen: 24.14 , 4[s]\n",
      "[6490/ 11000] Loss Dis: 0.71, Loss Gen: 27.56 , 4[s]\n",
      "[6500/ 11000] Loss Dis: 1.36, Loss Gen: 11.76 , 3[s]\n",
      "\n",
      "[[0.00 0.97 0.02 0.01 0.10]\n",
      " [0.03 0.00 0.05 0.00 0.00]\n",
      " [0.97 0.99 0.00 0.00 0.02]\n",
      " [0.00 0.00 0.97 0.00 0.92]\n",
      " [1.00 0.01 0.88 0.02 0.00]]\n",
      "\n",
      "[6510/ 11000] Loss Dis: 0.87, Loss Gen: 14.98 , 3[s]\n",
      "[6520/ 11000] Loss Dis: 0.61, Loss Gen: 21.22 , 3[s]\n",
      "[6530/ 11000] Loss Dis: 0.87, Loss Gen: 11.80 , 3[s]\n",
      "[6540/ 11000] Loss Dis: 0.38, Loss Gen: 25.96 , 3[s]\n",
      "[6550/ 11000] Loss Dis: 0.65, Loss Gen: 18.30 , 3[s]\n",
      "[6560/ 11000] Loss Dis: 0.80, Loss Gen: 15.89 , 3[s]\n",
      "[6570/ 11000] Loss Dis: 0.91, Loss Gen: 13.59 , 3[s]\n",
      "[6580/ 11000] Loss Dis: 0.37, Loss Gen: 27.76 , 3[s]\n",
      "[6590/ 11000] Loss Dis: 0.61, Loss Gen: 21.95 , 3[s]\n",
      "[6600/ 11000] Loss Dis: 0.56, Loss Gen: 24.21 , 3[s]\n",
      "\n",
      "[[0.00 0.98 0.02 0.01 0.13]\n",
      " [0.03 0.00 0.05 0.00 0.00]\n",
      " [0.97 0.99 0.00 0.00 0.03]\n",
      " [0.00 0.00 0.97 0.00 0.95]\n",
      " [1.00 0.01 0.86 0.01 0.00]]\n",
      "\n",
      "[6610/ 11000] Loss Dis: 0.81, Loss Gen: 18.45 , 3[s]\n",
      "[6620/ 11000] Loss Dis: 0.78, Loss Gen: 21.33 , 3[s]\n",
      "[6630/ 11000] Loss Dis: 0.71, Loss Gen: 21.12 , 3[s]\n",
      "[6640/ 11000] Loss Dis: 0.57, Loss Gen: 22.95 , 3[s]\n",
      "[6650/ 11000] Loss Dis: 0.54, Loss Gen: 21.49 , 3[s]\n",
      "[6660/ 11000] Loss Dis: 0.57, Loss Gen: 24.06 , 3[s]\n",
      "[6670/ 11000] Loss Dis: 0.54, Loss Gen: 23.93 , 3[s]\n",
      "[6680/ 11000] Loss Dis: 0.50, Loss Gen: 24.80 , 3[s]\n",
      "[6690/ 11000] Loss Dis: 0.52, Loss Gen: 24.08 , 3[s]\n",
      "[6700/ 11000] Loss Dis: 0.59, Loss Gen: 24.98 , 3[s]\n",
      "\n",
      "[[0.00 0.98 0.01 0.01 0.13]\n",
      " [0.03 0.00 0.04 0.00 0.01]\n",
      " [0.97 0.99 0.00 0.00 0.03]\n",
      " [0.00 0.00 0.98 0.00 0.96]\n",
      " [1.00 0.01 0.83 0.01 0.00]]\n",
      "\n",
      "[6710/ 11000] Loss Dis: 0.73, Loss Gen: 21.93 , 3[s]\n",
      "[6720/ 11000] Loss Dis: 0.87, Loss Gen: 21.38 , 3[s]\n",
      "[6730/ 11000] Loss Dis: 0.81, Loss Gen: 18.48 , 3[s]\n",
      "[6740/ 11000] Loss Dis: 0.44, Loss Gen: 27.49 , 3[s]\n",
      "[6750/ 11000] Loss Dis: 0.70, Loss Gen: 16.20 , 3[s]\n",
      "[6760/ 11000] Loss Dis: 0.52, Loss Gen: 24.14 , 3[s]\n",
      "[6770/ 11000] Loss Dis: 0.48, Loss Gen: 22.72 , 3[s]\n",
      "[6780/ 11000] Loss Dis: 0.50, Loss Gen: 22.57 , 3[s]\n",
      "[6790/ 11000] Loss Dis: 0.45, Loss Gen: 25.07 , 3[s]\n",
      "[6800/ 11000] Loss Dis: 0.53, Loss Gen: 25.82 , 3[s]\n",
      "\n",
      "[[0.00 0.98 0.01 0.01 0.10]\n",
      " [0.03 0.00 0.04 0.00 0.01]\n",
      " [0.97 0.99 0.00 0.00 0.02]\n",
      " [0.00 0.00 0.98 0.00 0.96]\n",
      " [1.00 0.01 0.85 0.01 0.00]]\n",
      "\n",
      "[6810/ 11000] Loss Dis: 0.77, Loss Gen: 26.91 , 3[s]\n",
      "[6820/ 11000] Loss Dis: 0.72, Loss Gen: 21.61 , 3[s]\n",
      "[6830/ 11000] Loss Dis: 0.60, Loss Gen: 21.64 , 3[s]\n",
      "[6840/ 11000] Loss Dis: 0.49, Loss Gen: 22.46 , 3[s]\n",
      "[6850/ 11000] Loss Dis: 0.45, Loss Gen: 23.84 , 3[s]\n",
      "[6860/ 11000] Loss Dis: 0.49, Loss Gen: 26.81 , 3[s]\n",
      "[6870/ 11000] Loss Dis: 1.01, Loss Gen: 24.14 , 3[s]\n",
      "[6880/ 11000] Loss Dis: 0.69, Loss Gen: 18.12 , 3[s]\n",
      "[6890/ 11000] Loss Dis: 0.69, Loss Gen: 18.94 , 3[s]\n",
      "[6900/ 11000] Loss Dis: 0.54, Loss Gen: 20.16 , 3[s]\n",
      "\n",
      "[[0.00 0.98 0.01 0.01 0.09]\n",
      " [0.03 0.00 0.04 0.00 0.01]\n",
      " [0.97 0.99 0.00 0.00 0.02]\n",
      " [0.00 0.00 0.98 0.00 0.97]\n",
      " [1.00 0.01 0.86 0.01 0.00]]\n",
      "\n",
      "[6910/ 11000] Loss Dis: 0.53, Loss Gen: 20.81 , 3[s]\n",
      "[6920/ 11000] Loss Dis: 0.56, Loss Gen: 21.55 , 3[s]\n",
      "[6930/ 11000] Loss Dis: 0.55, Loss Gen: 23.63 , 3[s]\n",
      "[6940/ 11000] Loss Dis: 0.49, Loss Gen: 24.02 , 3[s]\n",
      "[6950/ 11000] Loss Dis: 0.61, Loss Gen: 24.06 , 3[s]\n",
      "[6960/ 11000] Loss Dis: 0.72, Loss Gen: 25.02 , 3[s]\n",
      "[6970/ 11000] Loss Dis: 0.55, Loss Gen: 28.81 , 3[s]\n",
      "[6980/ 11000] Loss Dis: 0.46, Loss Gen: 27.39 , 3[s]\n",
      "[6990/ 11000] Loss Dis: 0.49, Loss Gen: 26.09 , 4[s]\n",
      "[7000/ 11000] Loss Dis: 0.85, Loss Gen: 24.75 , 4[s]\n",
      "\n",
      "[[0.00 0.98 0.01 0.00 0.08]\n",
      " [0.03 0.00 0.04 0.00 0.01]\n",
      " [0.97 0.99 0.00 0.00 0.02]\n",
      " [0.00 0.00 0.98 0.00 0.97]\n",
      " [1.00 0.01 0.86 0.01 0.00]]\n",
      "\n",
      "[7010/ 11000] Loss Dis: 0.57, Loss Gen: 24.31 , 3[s]\n",
      "[7020/ 11000] Loss Dis: 0.54, Loss Gen: 26.67 , 4[s]\n",
      "[7030/ 11000] Loss Dis: 0.50, Loss Gen: 22.78 , 4[s]\n",
      "[7040/ 11000] Loss Dis: 0.54, Loss Gen: 23.14 , 4[s]\n",
      "[7050/ 11000] Loss Dis: 0.57, Loss Gen: 18.50 , 4[s]\n",
      "[7060/ 11000] Loss Dis: 0.55, Loss Gen: 24.57 , 4[s]\n",
      "[7070/ 11000] Loss Dis: 0.46, Loss Gen: 25.39 , 4[s]\n",
      "[7080/ 11000] Loss Dis: 0.53, Loss Gen: 25.73 , 4[s]\n",
      "[7090/ 11000] Loss Dis: 1.17, Loss Gen: 21.51 , 4[s]\n",
      "[7100/ 11000] Loss Dis: 0.69, Loss Gen: 20.04 , 4[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.07]\n",
      " [0.02 0.00 0.03 0.00 0.01]\n",
      " [0.97 0.99 0.00 0.00 0.02]\n",
      " [0.00 0.00 0.98 0.00 0.97]\n",
      " [1.00 0.01 0.87 0.01 0.00]]\n",
      "\n",
      "[7110/ 11000] Loss Dis: 0.63, Loss Gen: 21.73 , 4[s]\n",
      "[7120/ 11000] Loss Dis: 0.49, Loss Gen: 27.17 , 4[s]\n",
      "[7130/ 11000] Loss Dis: 0.53, Loss Gen: 23.09 , 4[s]\n",
      "[7140/ 11000] Loss Dis: 0.46, Loss Gen: 24.84 , 4[s]\n",
      "[7150/ 11000] Loss Dis: 0.52, Loss Gen: 26.12 , 4[s]\n",
      "[7160/ 11000] Loss Dis: 0.59, Loss Gen: 19.37 , 4[s]\n",
      "[7170/ 11000] Loss Dis: 1.42, Loss Gen: 23.61 , 4[s]\n",
      "[7180/ 11000] Loss Dis: 1.01, Loss Gen: 17.04 , 4[s]\n",
      "[7190/ 11000] Loss Dis: 0.81, Loss Gen: 23.46 , 4[s]\n",
      "[7200/ 11000] Loss Dis: 0.76, Loss Gen: 20.53 , 3[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.06]\n",
      " [0.02 0.00 0.03 0.00 0.00]\n",
      " [0.97 0.99 0.00 0.00 0.02]\n",
      " [0.00 0.00 0.98 0.00 0.97]\n",
      " [1.00 0.01 0.90 0.01 0.00]]\n",
      "\n",
      "[7210/ 11000] Loss Dis: 0.68, Loss Gen: 18.44 , 3[s]\n",
      "[7220/ 11000] Loss Dis: 0.57, Loss Gen: 19.66 , 4[s]\n",
      "[7230/ 11000] Loss Dis: 0.59, Loss Gen: 20.48 , 4[s]\n",
      "[7240/ 11000] Loss Dis: 0.56, Loss Gen: 23.42 , 4[s]\n",
      "[7250/ 11000] Loss Dis: 0.52, Loss Gen: 23.04 , 4[s]\n",
      "[7260/ 11000] Loss Dis: 0.44, Loss Gen: 23.93 , 4[s]\n",
      "[7270/ 11000] Loss Dis: 0.46, Loss Gen: 24.56 , 4[s]\n",
      "[7280/ 11000] Loss Dis: 1.18, Loss Gen: 22.87 , 4[s]\n",
      "[7290/ 11000] Loss Dis: 1.01, Loss Gen: 16.71 , 3[s]\n",
      "[7300/ 11000] Loss Dis: 0.76, Loss Gen: 22.48 , 3[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.06]\n",
      " [0.02 0.00 0.03 0.00 0.00]\n",
      " [0.97 0.99 0.00 0.00 0.03]\n",
      " [0.00 0.00 0.98 0.00 0.98]\n",
      " [1.00 0.00 0.92 0.01 0.00]]\n",
      "\n",
      "[7310/ 11000] Loss Dis: 0.68, Loss Gen: 15.25 , 3[s]\n",
      "[7320/ 11000] Loss Dis: 0.68, Loss Gen: 18.31 , 3[s]\n",
      "[7330/ 11000] Loss Dis: 0.64, Loss Gen: 20.95 , 3[s]\n",
      "[7340/ 11000] Loss Dis: 0.59, Loss Gen: 20.26 , 3[s]\n",
      "[7350/ 11000] Loss Dis: 0.53, Loss Gen: 22.09 , 3[s]\n",
      "[7360/ 11000] Loss Dis: 0.55, Loss Gen: 22.18 , 3[s]\n",
      "[7370/ 11000] Loss Dis: 0.49, Loss Gen: 23.65 , 3[s]\n",
      "[7380/ 11000] Loss Dis: 0.47, Loss Gen: 27.21 , 3[s]\n",
      "[7390/ 11000] Loss Dis: 0.82, Loss Gen: 24.60 , 3[s]\n",
      "[7400/ 11000] Loss Dis: 0.84, Loss Gen: 22.14 , 3[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.06]\n",
      " [0.01 0.00 0.03 0.00 0.00]\n",
      " [0.97 0.99 0.00 0.00 0.03]\n",
      " [0.00 0.00 0.98 0.00 0.98]\n",
      " [1.00 0.00 0.93 0.01 0.00]]\n",
      "\n",
      "[7410/ 11000] Loss Dis: 0.54, Loss Gen: 21.80 , 3[s]\n",
      "[7420/ 11000] Loss Dis: 0.53, Loss Gen: 22.34 , 3[s]\n",
      "[7430/ 11000] Loss Dis: 0.56, Loss Gen: 23.70 , 3[s]\n",
      "[7440/ 11000] Loss Dis: 0.54, Loss Gen: 28.86 , 3[s]\n",
      "[7450/ 11000] Loss Dis: 0.62, Loss Gen: 26.42 , 3[s]\n",
      "[7460/ 11000] Loss Dis: 0.55, Loss Gen: 22.97 , 3[s]\n",
      "[7470/ 11000] Loss Dis: 0.67, Loss Gen: 24.21 , 3[s]\n",
      "[7480/ 11000] Loss Dis: 0.59, Loss Gen: 26.36 , 3[s]\n",
      "[7490/ 11000] Loss Dis: 0.73, Loss Gen: 24.24 , 3[s]\n",
      "[7500/ 11000] Loss Dis: 1.03, Loss Gen: 24.16 , 3[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.05]\n",
      " [0.01 0.00 0.03 0.00 0.00]\n",
      " [0.97 0.99 0.00 0.00 0.03]\n",
      " [0.00 0.00 0.98 0.00 0.98]\n",
      " [1.00 0.00 0.94 0.01 0.00]]\n",
      "\n",
      "[7510/ 11000] Loss Dis: 0.70, Loss Gen: 21.76 , 3[s]\n",
      "[7520/ 11000] Loss Dis: 0.65, Loss Gen: 19.86 , 3[s]\n",
      "[7530/ 11000] Loss Dis: 0.59, Loss Gen: 21.51 , 3[s]\n",
      "[7540/ 11000] Loss Dis: 0.54, Loss Gen: 21.93 , 3[s]\n",
      "[7550/ 11000] Loss Dis: 0.48, Loss Gen: 33.22 , 3[s]\n",
      "[7560/ 11000] Loss Dis: 0.48, Loss Gen: 25.60 , 3[s]\n",
      "[7570/ 11000] Loss Dis: 0.50, Loss Gen: 27.67 , 3[s]\n",
      "[7580/ 11000] Loss Dis: 0.48, Loss Gen: 26.69 , 3[s]\n",
      "[7590/ 11000] Loss Dis: 1.58, Loss Gen: 22.99 , 3[s]\n",
      "[7600/ 11000] Loss Dis: 0.95, Loss Gen: 18.51 , 3[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.05]\n",
      " [0.01 0.00 0.03 0.00 0.00]\n",
      " [0.97 0.99 0.00 0.00 0.03]\n",
      " [0.00 0.00 0.98 0.00 0.98]\n",
      " [1.00 0.00 0.96 0.01 0.00]]\n",
      "\n",
      "[7610/ 11000] Loss Dis: 0.77, Loss Gen: 18.59 , 2[s]\n",
      "[7620/ 11000] Loss Dis: 0.64, Loss Gen: 20.63 , 3[s]\n",
      "[7630/ 11000] Loss Dis: 0.56, Loss Gen: 22.47 , 2[s]\n",
      "[7640/ 11000] Loss Dis: 0.57, Loss Gen: 20.78 , 3[s]\n",
      "[7650/ 11000] Loss Dis: 0.57, Loss Gen: 21.99 , 2[s]\n",
      "[7660/ 11000] Loss Dis: 0.46, Loss Gen: 23.77 , 3[s]\n",
      "[7670/ 11000] Loss Dis: 0.49, Loss Gen: 23.96 , 2[s]\n",
      "[7680/ 11000] Loss Dis: 0.58, Loss Gen: 24.61 , 3[s]\n",
      "[7690/ 11000] Loss Dis: 0.63, Loss Gen: 25.03 , 3[s]\n",
      "[7700/ 11000] Loss Dis: 0.65, Loss Gen: 24.56 , 3[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.05]\n",
      " [0.01 0.00 0.02 0.00 0.00]\n",
      " [0.97 0.99 0.00 0.00 0.03]\n",
      " [0.00 0.00 0.98 0.00 0.98]\n",
      " [1.00 0.00 0.96 0.01 0.00]]\n",
      "\n",
      "[7710/ 11000] Loss Dis: 0.67, Loss Gen: 21.53 , 2[s]\n",
      "[7720/ 11000] Loss Dis: 0.58, Loss Gen: 23.03 , 3[s]\n",
      "[7730/ 11000] Loss Dis: 0.54, Loss Gen: 23.03 , 3[s]\n",
      "[7740/ 11000] Loss Dis: 0.49, Loss Gen: 24.29 , 2[s]\n",
      "[7750/ 11000] Loss Dis: 0.41, Loss Gen: 31.66 , 2[s]\n",
      "[7760/ 11000] Loss Dis: 0.50, Loss Gen: 26.71 , 2[s]\n",
      "[7770/ 11000] Loss Dis: 0.73, Loss Gen: 24.32 , 3[s]\n",
      "[7780/ 11000] Loss Dis: 0.60, Loss Gen: 24.02 , 3[s]\n",
      "[7790/ 11000] Loss Dis: 0.58, Loss Gen: 23.99 , 2[s]\n",
      "[7800/ 11000] Loss Dis: 0.53, Loss Gen: 24.56 , 3[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.05]\n",
      " [0.01 0.00 0.02 0.01 0.00]\n",
      " [0.97 0.99 0.00 0.00 0.03]\n",
      " [0.00 0.00 0.98 0.00 0.98]\n",
      " [1.00 0.00 0.97 0.00 0.00]]\n",
      "\n",
      "[7810/ 11000] Loss Dis: 0.48, Loss Gen: 26.24 , 2[s]\n",
      "[7820/ 11000] Loss Dis: 0.36, Loss Gen: 37.77 , 3[s]\n",
      "[7830/ 11000] Loss Dis: 0.68, Loss Gen: 23.43 , 2[s]\n",
      "[7840/ 11000] Loss Dis: 0.87, Loss Gen: 20.76 , 2[s]\n",
      "[7850/ 11000] Loss Dis: 0.68, Loss Gen: 21.87 , 2[s]\n",
      "[7860/ 11000] Loss Dis: 0.64, Loss Gen: 21.20 , 2[s]\n",
      "[7870/ 11000] Loss Dis: 0.67, Loss Gen: 22.34 , 2[s]\n",
      "[7880/ 11000] Loss Dis: 0.64, Loss Gen: 22.67 , 2[s]\n",
      "[7890/ 11000] Loss Dis: 0.63, Loss Gen: 24.17 , 2[s]\n",
      "[7900/ 11000] Loss Dis: 0.57, Loss Gen: 21.87 , 2[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.05]\n",
      " [0.01 0.00 0.02 0.00 0.00]\n",
      " [0.97 0.99 0.00 0.00 0.03]\n",
      " [0.00 0.00 0.98 0.00 0.99]\n",
      " [1.00 0.00 0.97 0.00 0.00]]\n",
      "\n",
      "[7910/ 11000] Loss Dis: 0.51, Loss Gen: 28.57 , 3[s]\n",
      "[7920/ 11000] Loss Dis: 0.51, Loss Gen: 23.85 , 3[s]\n",
      "[7930/ 11000] Loss Dis: 0.67, Loss Gen: 23.32 , 3[s]\n",
      "[7940/ 11000] Loss Dis: 0.56, Loss Gen: 23.68 , 2[s]\n",
      "[7950/ 11000] Loss Dis: 0.51, Loss Gen: 21.96 , 3[s]\n",
      "[7960/ 11000] Loss Dis: 0.52, Loss Gen: 25.88 , 3[s]\n",
      "[7970/ 11000] Loss Dis: 0.52, Loss Gen: 25.15 , 3[s]\n",
      "[7980/ 11000] Loss Dis: 0.46, Loss Gen: 26.53 , 3[s]\n",
      "[7990/ 11000] Loss Dis: 0.51, Loss Gen: 26.90 , 3[s]\n",
      "[8000/ 11000] Loss Dis: 0.72, Loss Gen: 24.55 , 3[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.04]\n",
      " [0.01 0.00 0.02 0.00 0.00]\n",
      " [0.97 0.99 0.00 0.00 0.03]\n",
      " [0.00 0.00 0.98 0.00 0.99]\n",
      " [1.00 0.00 0.97 0.00 0.00]]\n",
      "\n",
      "[8010/ 11000] Loss Dis: 0.63, Loss Gen: 24.28 , 3[s]\n",
      "[8020/ 11000] Loss Dis: 0.54, Loss Gen: 24.04 , 3[s]\n",
      "[8030/ 11000] Loss Dis: 0.55, Loss Gen: 24.38 , 3[s]\n",
      "[8040/ 11000] Loss Dis: 0.61, Loss Gen: 25.19 , 3[s]\n",
      "[8050/ 11000] Loss Dis: 0.81, Loss Gen: 20.42 , 3[s]\n",
      "[8060/ 11000] Loss Dis: 0.58, Loss Gen: 22.46 , 3[s]\n",
      "[8070/ 11000] Loss Dis: 0.60, Loss Gen: 26.08 , 3[s]\n",
      "[8080/ 11000] Loss Dis: 0.56, Loss Gen: 25.04 , 3[s]\n",
      "[8090/ 11000] Loss Dis: 0.38, Loss Gen: 32.71 , 3[s]\n",
      "[8100/ 11000] Loss Dis: 0.56, Loss Gen: 24.92 , 3[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.04]\n",
      " [0.01 0.00 0.02 0.00 0.00]\n",
      " [0.97 0.99 0.00 0.00 0.03]\n",
      " [0.00 0.00 0.99 0.00 0.99]\n",
      " [1.00 0.00 0.97 0.00 0.00]]\n",
      "\n",
      "[8110/ 11000] Loss Dis: 1.30, Loss Gen: 24.03 , 4[s]\n",
      "[8120/ 11000] Loss Dis: 1.11, Loss Gen: 19.93 , 4[s]\n",
      "[8130/ 11000] Loss Dis: 0.79, Loss Gen: 19.11 , 3[s]\n",
      "[8140/ 11000] Loss Dis: 0.71, Loss Gen: 21.27 , 3[s]\n",
      "[8150/ 11000] Loss Dis: 0.63, Loss Gen: 20.61 , 3[s]\n",
      "[8160/ 11000] Loss Dis: 0.54, Loss Gen: 23.52 , 3[s]\n",
      "[8170/ 11000] Loss Dis: 0.58, Loss Gen: 24.50 , 4[s]\n",
      "[8180/ 11000] Loss Dis: 0.71, Loss Gen: 23.29 , 4[s]\n",
      "[8190/ 11000] Loss Dis: 0.54, Loss Gen: 23.67 , 4[s]\n",
      "[8200/ 11000] Loss Dis: 0.64, Loss Gen: 18.41 , 4[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.04]\n",
      " [0.01 0.00 0.02 0.00 0.00]\n",
      " [0.96 0.99 0.00 0.00 0.03]\n",
      " [0.00 0.00 0.99 0.00 0.99]\n",
      " [1.00 0.00 0.97 0.00 0.00]]\n",
      "\n",
      "[8210/ 11000] Loss Dis: 0.60, Loss Gen: 26.72 , 4[s]\n",
      "[8220/ 11000] Loss Dis: 0.52, Loss Gen: 27.86 , 4[s]\n",
      "[8230/ 11000] Loss Dis: 0.56, Loss Gen: 25.74 , 4[s]\n",
      "[8240/ 11000] Loss Dis: 0.94, Loss Gen: 24.94 , 4[s]\n",
      "[8250/ 11000] Loss Dis: 1.00, Loss Gen: 22.35 , 3[s]\n",
      "[8260/ 11000] Loss Dis: 0.75, Loss Gen: 18.93 , 3[s]\n",
      "[8270/ 11000] Loss Dis: 0.79, Loss Gen: 19.20 , 4[s]\n",
      "[8280/ 11000] Loss Dis: 0.65, Loss Gen: 20.58 , 3[s]\n",
      "[8290/ 11000] Loss Dis: 0.66, Loss Gen: 19.37 , 4[s]\n",
      "[8300/ 11000] Loss Dis: 0.60, Loss Gen: 22.45 , 4[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.04]\n",
      " [0.01 0.00 0.01 0.00 0.00]\n",
      " [0.95 0.99 0.00 0.00 0.03]\n",
      " [0.00 0.00 0.99 0.00 0.99]\n",
      " [1.00 0.00 0.97 0.00 0.00]]\n",
      "\n",
      "[8310/ 11000] Loss Dis: 0.66, Loss Gen: 22.12 , 4[s]\n",
      "[8320/ 11000] Loss Dis: 0.58, Loss Gen: 24.71 , 4[s]\n",
      "[8330/ 11000] Loss Dis: 0.65, Loss Gen: 26.26 , 4[s]\n",
      "[8340/ 11000] Loss Dis: 0.56, Loss Gen: 26.19 , 4[s]\n",
      "[8350/ 11000] Loss Dis: 0.54, Loss Gen: 22.47 , 4[s]\n",
      "[8360/ 11000] Loss Dis: 0.93, Loss Gen: 24.85 , 4[s]\n",
      "[8370/ 11000] Loss Dis: 0.76, Loss Gen: 24.26 , 4[s]\n",
      "[8380/ 11000] Loss Dis: 0.63, Loss Gen: 25.16 , 4[s]\n",
      "[8390/ 11000] Loss Dis: 0.73, Loss Gen: 21.70 , 4[s]\n",
      "[8400/ 11000] Loss Dis: 0.59, Loss Gen: 22.45 , 4[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.04]\n",
      " [0.01 0.00 0.01 0.00 0.00]\n",
      " [0.94 0.99 0.00 0.00 0.03]\n",
      " [0.00 0.00 0.99 0.00 0.99]\n",
      " [1.00 0.00 0.97 0.00 0.00]]\n",
      "\n",
      "[8410/ 11000] Loss Dis: 0.58, Loss Gen: 22.77 , 4[s]\n",
      "[8420/ 11000] Loss Dis: 0.65, Loss Gen: 25.84 , 4[s]\n",
      "[8430/ 11000] Loss Dis: 0.78, Loss Gen: 22.87 , 4[s]\n",
      "[8440/ 11000] Loss Dis: 0.68, Loss Gen: 23.52 , 4[s]\n",
      "[8450/ 11000] Loss Dis: 0.63, Loss Gen: 25.35 , 4[s]\n",
      "[8460/ 11000] Loss Dis: 0.58, Loss Gen: 24.83 , 4[s]\n",
      "[8470/ 11000] Loss Dis: 0.57, Loss Gen: 30.77 , 4[s]\n",
      "[8480/ 11000] Loss Dis: 0.81, Loss Gen: 21.00 , 4[s]\n",
      "[8490/ 11000] Loss Dis: 0.62, Loss Gen: 22.15 , 4[s]\n",
      "[8500/ 11000] Loss Dis: 0.51, Loss Gen: 22.69 , 3[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.04]\n",
      " [0.01 0.00 0.01 0.00 0.00]\n",
      " [0.93 0.99 0.00 0.00 0.02]\n",
      " [0.01 0.00 0.99 0.00 0.99]\n",
      " [1.00 0.00 0.98 0.00 0.00]]\n",
      "\n",
      "[8510/ 11000] Loss Dis: 0.54, Loss Gen: 23.43 , 4[s]\n",
      "[8520/ 11000] Loss Dis: 0.68, Loss Gen: 23.28 , 4[s]\n",
      "[8530/ 11000] Loss Dis: 0.62, Loss Gen: 24.23 , 4[s]\n",
      "[8540/ 11000] Loss Dis: 0.63, Loss Gen: 23.63 , 4[s]\n",
      "[8550/ 11000] Loss Dis: 0.61, Loss Gen: 24.55 , 4[s]\n",
      "[8560/ 11000] Loss Dis: 0.53, Loss Gen: 23.68 , 4[s]\n",
      "[8570/ 11000] Loss Dis: 0.54, Loss Gen: 24.21 , 4[s]\n",
      "[8580/ 11000] Loss Dis: 0.72, Loss Gen: 25.27 , 4[s]\n",
      "[8590/ 11000] Loss Dis: 0.52, Loss Gen: 25.00 , 4[s]\n",
      "[8600/ 11000] Loss Dis: 0.73, Loss Gen: 25.32 , 4[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.04]\n",
      " [0.01 0.00 0.01 0.00 0.00]\n",
      " [0.90 0.99 0.00 0.00 0.03]\n",
      " [0.01 0.00 0.99 0.00 0.99]\n",
      " [1.00 0.00 0.98 0.00 0.00]]\n",
      "\n",
      "[8610/ 11000] Loss Dis: 0.56, Loss Gen: 24.94 , 4[s]\n",
      "[8620/ 11000] Loss Dis: 0.51, Loss Gen: 23.69 , 4[s]\n",
      "[8630/ 11000] Loss Dis: 0.42, Loss Gen: 25.06 , 4[s]\n",
      "[8640/ 11000] Loss Dis: 1.06, Loss Gen: 40.25 , 4[s]\n",
      "[8650/ 11000] Loss Dis: 0.76, Loss Gen: 24.15 , 3[s]\n",
      "[8660/ 11000] Loss Dis: 0.70, Loss Gen: 24.13 , 3[s]\n",
      "[8670/ 11000] Loss Dis: 0.64, Loss Gen: 23.46 , 4[s]\n",
      "[8680/ 11000] Loss Dis: 0.60, Loss Gen: 28.96 , 4[s]\n",
      "[8690/ 11000] Loss Dis: 0.79, Loss Gen: 23.72 , 4[s]\n",
      "[8700/ 11000] Loss Dis: 0.66, Loss Gen: 23.50 , 4[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.04]\n",
      " [0.01 0.00 0.01 0.00 0.00]\n",
      " [0.80 0.99 0.00 0.00 0.03]\n",
      " [0.01 0.00 0.99 0.00 0.99]\n",
      " [1.00 0.00 0.98 0.00 0.00]]\n",
      "\n",
      "[8710/ 11000] Loss Dis: 0.60, Loss Gen: 24.09 , 4[s]\n",
      "[8720/ 11000] Loss Dis: 0.38, Loss Gen: 40.53 , 4[s]\n",
      "[8730/ 11000] Loss Dis: 0.49, Loss Gen: 31.47 , 4[s]\n",
      "[8740/ 11000] Loss Dis: 0.70, Loss Gen: 24.57 , 4[s]\n",
      "[8750/ 11000] Loss Dis: 0.79, Loss Gen: 24.67 , 4[s]\n",
      "[8760/ 11000] Loss Dis: 0.69, Loss Gen: 22.54 , 4[s]\n",
      "[8770/ 11000] Loss Dis: 0.57, Loss Gen: 29.89 , 4[s]\n",
      "[8780/ 11000] Loss Dis: 0.50, Loss Gen: 25.73 , 4[s]\n",
      "[8790/ 11000] Loss Dis: 0.69, Loss Gen: 30.34 , 4[s]\n",
      "[8800/ 11000] Loss Dis: 0.91, Loss Gen: 26.30 , 4[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.01 0.04]\n",
      " [0.01 0.00 0.01 0.00 0.00]\n",
      " [0.60 0.99 0.00 0.00 0.02]\n",
      " [0.01 0.00 0.99 0.00 0.99]\n",
      " [1.00 0.00 0.98 0.00 0.00]]\n",
      "\n",
      "[8810/ 11000] Loss Dis: 0.93, Loss Gen: 27.48 , 4[s]\n",
      "[8820/ 11000] Loss Dis: 0.71, Loss Gen: 22.96 , 4[s]\n",
      "[8830/ 11000] Loss Dis: 0.56, Loss Gen: 26.41 , 4[s]\n",
      "[8840/ 11000] Loss Dis: 0.54, Loss Gen: 23.96 , 4[s]\n",
      "[8850/ 11000] Loss Dis: 0.34, Loss Gen: 36.76 , 4[s]\n",
      "[8860/ 11000] Loss Dis: 0.55, Loss Gen: 28.88 , 4[s]\n",
      "[8870/ 11000] Loss Dis: 0.62, Loss Gen: 28.25 , 4[s]\n",
      "[8880/ 11000] Loss Dis: 0.63, Loss Gen: 27.70 , 4[s]\n",
      "[8890/ 11000] Loss Dis: 0.63, Loss Gen: 25.07 , 4[s]\n",
      "[8900/ 11000] Loss Dis: 0.69, Loss Gen: 21.68 , 4[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.01 0.04]\n",
      " [0.01 0.00 0.01 0.00 0.00]\n",
      " [0.24 0.99 0.00 0.00 0.02]\n",
      " [0.01 0.00 1.00 0.00 0.99]\n",
      " [1.00 0.00 0.98 0.00 0.00]]\n",
      "\n",
      "[8910/ 11000] Loss Dis: 0.62, Loss Gen: 23.96 , 4[s]\n",
      "[8920/ 11000] Loss Dis: 0.59, Loss Gen: 29.01 , 4[s]\n",
      "[8930/ 11000] Loss Dis: 0.54, Loss Gen: 25.20 , 4[s]\n",
      "[8940/ 11000] Loss Dis: 0.49, Loss Gen: 26.91 , 4[s]\n",
      "[8950/ 11000] Loss Dis: 0.93, Loss Gen: 25.75 , 4[s]\n",
      "[8960/ 11000] Loss Dis: 0.83, Loss Gen: 30.07 , 4[s]\n",
      "[8970/ 11000] Loss Dis: 0.65, Loss Gen: 25.85 , 4[s]\n",
      "[8980/ 11000] Loss Dis: 0.55, Loss Gen: 26.32 , 4[s]\n",
      "[8990/ 11000] Loss Dis: 0.57, Loss Gen: 26.73 , 4[s]\n",
      "[9000/ 11000] Loss Dis: 0.56, Loss Gen: 28.04 , 4[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.05]\n",
      " [0.02 0.00 0.01 0.00 0.00]\n",
      " [0.08 0.99 0.00 0.00 0.03]\n",
      " [0.01 0.00 1.00 0.00 0.99]\n",
      " [1.00 0.00 0.98 0.00 0.00]]\n",
      "\n",
      "[9010/ 11000] Loss Dis: 0.53, Loss Gen: 26.94 , 4[s]\n",
      "[9020/ 11000] Loss Dis: 1.49, Loss Gen: 21.82 , 3[s]\n",
      "[9030/ 11000] Loss Dis: 0.89, Loss Gen: 22.38 , 3[s]\n",
      "[9040/ 11000] Loss Dis: 0.71, Loss Gen: 25.25 , 3[s]\n",
      "[9050/ 11000] Loss Dis: 0.57, Loss Gen: 26.05 , 3[s]\n",
      "[9060/ 11000] Loss Dis: 0.56, Loss Gen: 26.38 , 3[s]\n",
      "[9070/ 11000] Loss Dis: 0.72, Loss Gen: 21.21 , 3[s]\n",
      "[9080/ 11000] Loss Dis: 0.62, Loss Gen: 25.45 , 3[s]\n",
      "[9090/ 11000] Loss Dis: 0.57, Loss Gen: 26.81 , 3[s]\n",
      "[9100/ 11000] Loss Dis: 0.58, Loss Gen: 26.78 , 3[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.01 0.05]\n",
      " [0.04 0.00 0.01 0.00 0.00]\n",
      " [0.05 0.99 0.00 0.00 0.03]\n",
      " [0.01 0.00 1.00 0.00 0.99]\n",
      " [1.00 0.00 0.98 0.00 0.00]]\n",
      "\n",
      "[9110/ 11000] Loss Dis: 0.56, Loss Gen: 27.91 , 3[s]\n",
      "[9120/ 11000] Loss Dis: 0.55, Loss Gen: 27.37 , 3[s]\n",
      "[9130/ 11000] Loss Dis: 0.50, Loss Gen: 28.96 , 3[s]\n",
      "[9140/ 11000] Loss Dis: 0.56, Loss Gen: 28.72 , 3[s]\n",
      "[9150/ 11000] Loss Dis: 0.62, Loss Gen: 28.71 , 3[s]\n",
      "[9160/ 11000] Loss Dis: 0.66, Loss Gen: 28.93 , 3[s]\n",
      "[9170/ 11000] Loss Dis: 0.63, Loss Gen: 27.37 , 3[s]\n",
      "[9180/ 11000] Loss Dis: 0.59, Loss Gen: 27.78 , 3[s]\n",
      "[9190/ 11000] Loss Dis: 0.60, Loss Gen: 27.29 , 3[s]\n",
      "[9200/ 11000] Loss Dis: 0.53, Loss Gen: 27.47 , 3[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.06]\n",
      " [0.05 0.00 0.01 0.00 0.00]\n",
      " [0.04 0.99 0.00 0.00 0.03]\n",
      " [0.01 0.00 1.00 0.00 0.99]\n",
      " [1.00 0.00 0.98 0.01 0.00]]\n",
      "\n",
      "[9210/ 11000] Loss Dis: 0.60, Loss Gen: 29.07 , 3[s]\n",
      "[9220/ 11000] Loss Dis: 0.53, Loss Gen: 28.01 , 3[s]\n",
      "[9230/ 11000] Loss Dis: 0.53, Loss Gen: 28.31 , 3[s]\n",
      "[9240/ 11000] Loss Dis: 0.67, Loss Gen: 32.67 , 3[s]\n",
      "[9250/ 11000] Loss Dis: 0.69, Loss Gen: 26.94 , 3[s]\n",
      "[9260/ 11000] Loss Dis: 0.67, Loss Gen: 25.00 , 3[s]\n",
      "[9270/ 11000] Loss Dis: 0.53, Loss Gen: 28.32 , 3[s]\n",
      "[9280/ 11000] Loss Dis: 0.55, Loss Gen: 28.18 , 3[s]\n",
      "[9290/ 11000] Loss Dis: 0.58, Loss Gen: 26.84 , 3[s]\n",
      "[9300/ 11000] Loss Dis: 0.58, Loss Gen: 27.40 , 3[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.06]\n",
      " [0.05 0.00 0.01 0.00 0.00]\n",
      " [0.03 0.99 0.00 0.00 0.03]\n",
      " [0.01 0.00 1.00 0.00 0.99]\n",
      " [1.00 0.00 0.99 0.01 0.00]]\n",
      "\n",
      "[9310/ 11000] Loss Dis: 0.58, Loss Gen: 30.51 , 3[s]\n",
      "[9320/ 11000] Loss Dis: 0.66, Loss Gen: 28.60 , 3[s]\n",
      "[9330/ 11000] Loss Dis: 0.68, Loss Gen: 27.95 , 3[s]\n",
      "[9340/ 11000] Loss Dis: 0.59, Loss Gen: 28.51 , 3[s]\n",
      "[9350/ 11000] Loss Dis: 0.56, Loss Gen: 26.03 , 3[s]\n",
      "[9360/ 11000] Loss Dis: 0.59, Loss Gen: 28.86 , 3[s]\n",
      "[9370/ 11000] Loss Dis: 0.55, Loss Gen: 27.80 , 3[s]\n",
      "[9380/ 11000] Loss Dis: 0.50, Loss Gen: 29.83 , 3[s]\n",
      "[9390/ 11000] Loss Dis: 0.58, Loss Gen: 29.78 , 3[s]\n",
      "[9400/ 11000] Loss Dis: 0.77, Loss Gen: 28.58 , 3[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.06]\n",
      " [0.05 0.00 0.01 0.00 0.00]\n",
      " [0.02 0.99 0.00 0.00 0.02]\n",
      " [0.01 0.00 1.00 0.00 0.99]\n",
      " [1.00 0.00 0.99 0.01 0.00]]\n",
      "\n",
      "[9410/ 11000] Loss Dis: 0.66, Loss Gen: 26.32 , 3[s]\n",
      "[9420/ 11000] Loss Dis: 0.64, Loss Gen: 30.01 , 3[s]\n",
      "[9430/ 11000] Loss Dis: 0.59, Loss Gen: 28.69 , 3[s]\n",
      "[9440/ 11000] Loss Dis: 0.33, Loss Gen: 42.03 , 2[s]\n",
      "[9450/ 11000] Loss Dis: 0.56, Loss Gen: 39.86 , 3[s]\n",
      "[9460/ 11000] Loss Dis: 0.43, Loss Gen: 45.78 , 3[s]\n",
      "[9470/ 11000] Loss Dis: 0.69, Loss Gen: 27.54 , 3[s]\n",
      "[9480/ 11000] Loss Dis: 0.60, Loss Gen: 28.53 , 3[s]\n",
      "[9490/ 11000] Loss Dis: 0.54, Loss Gen: 27.93 , 2[s]\n",
      "[9500/ 11000] Loss Dis: 0.64, Loss Gen: 27.78 , 3[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.07]\n",
      " [0.05 0.00 0.01 0.00 0.00]\n",
      " [0.02 0.99 0.00 0.00 0.02]\n",
      " [0.01 0.00 1.00 0.00 0.99]\n",
      " [1.00 0.00 0.99 0.00 0.00]]\n",
      "\n",
      "[9510/ 11000] Loss Dis: 0.56, Loss Gen: 27.93 , 2[s]\n",
      "[9520/ 11000] Loss Dis: 0.53, Loss Gen: 28.26 , 2[s]\n",
      "[9530/ 11000] Loss Dis: 0.65, Loss Gen: 25.26 , 2[s]\n",
      "[9540/ 11000] Loss Dis: 0.57, Loss Gen: 27.88 , 2[s]\n",
      "[9550/ 11000] Loss Dis: 0.75, Loss Gen: 26.34 , 2[s]\n",
      "[9560/ 11000] Loss Dis: 0.70, Loss Gen: 24.97 , 2[s]\n",
      "[9570/ 11000] Loss Dis: 0.56, Loss Gen: 27.12 , 2[s]\n",
      "[9580/ 11000] Loss Dis: 0.57, Loss Gen: 26.87 , 2[s]\n",
      "[9590/ 11000] Loss Dis: 0.51, Loss Gen: 28.96 , 2[s]\n",
      "[9600/ 11000] Loss Dis: 1.20, Loss Gen: 20.25 , 2[s]\n",
      "\n",
      "[[0.00 0.99 0.01 0.00 0.06]\n",
      " [0.05 0.00 0.01 0.00 0.00]\n",
      " [0.02 0.99 0.00 0.00 0.03]\n",
      " [0.02 0.00 1.00 0.00 0.99]\n",
      " [1.00 0.00 0.99 0.00 0.00]]\n",
      "\n",
      "[9610/ 11000] Loss Dis: 0.79, Loss Gen: 31.67 , 2[s]\n",
      "[9620/ 11000] Loss Dis: 0.84, Loss Gen: 15.99 , 2[s]\n",
      "[9630/ 11000] Loss Dis: 0.75, Loss Gen: 18.67 , 2[s]\n",
      "[9640/ 11000] Loss Dis: 0.47, Loss Gen: 29.25 , 2[s]\n",
      "[9650/ 11000] Loss Dis: 0.63, Loss Gen: 21.65 , 2[s]\n",
      "[9660/ 11000] Loss Dis: 0.61, Loss Gen: 21.53 , 2[s]\n",
      "[9670/ 11000] Loss Dis: 0.60, Loss Gen: 23.08 , 2[s]\n",
      "[9680/ 11000] Loss Dis: 0.58, Loss Gen: 23.54 , 2[s]\n",
      "[9690/ 11000] Loss Dis: 0.55, Loss Gen: 24.61 , 2[s]\n",
      "[9700/ 11000] Loss Dis: 0.54, Loss Gen: 26.11 , 2[s]\n",
      "\n",
      "[[0.00 1.00 0.01 0.00 0.06]\n",
      " [0.04 0.00 0.01 0.00 0.00]\n",
      " [0.01 0.99 0.00 0.00 0.02]\n",
      " [0.02 0.00 1.00 0.00 0.99]\n",
      " [1.00 0.00 0.99 0.00 0.00]]\n",
      "\n",
      "[9710/ 11000] Loss Dis: 0.57, Loss Gen: 26.75 , 2[s]\n",
      "[9720/ 11000] Loss Dis: 0.57, Loss Gen: 26.56 , 2[s]\n",
      "[9730/ 11000] Loss Dis: 0.54, Loss Gen: 27.46 , 2[s]\n",
      "[9740/ 11000] Loss Dis: 0.54, Loss Gen: 27.05 , 2[s]\n",
      "[9750/ 11000] Loss Dis: 0.53, Loss Gen: 27.17 , 2[s]\n",
      "[9760/ 11000] Loss Dis: 0.89, Loss Gen: 26.09 , 2[s]\n",
      "[9770/ 11000] Loss Dis: 0.90, Loss Gen: 30.53 , 2[s]\n",
      "[9780/ 11000] Loss Dis: 0.72, Loss Gen: 23.89 , 2[s]\n",
      "[9790/ 11000] Loss Dis: 0.64, Loss Gen: 24.28 , 2[s]\n",
      "[9800/ 11000] Loss Dis: 0.63, Loss Gen: 26.22 , 2[s]\n",
      "\n",
      "[[0.00 1.00 0.01 0.00 0.06]\n",
      " [0.04 0.00 0.01 0.00 0.00]\n",
      " [0.01 0.99 0.00 0.00 0.02]\n",
      " [0.02 0.00 1.00 0.00 1.00]\n",
      " [1.00 0.00 0.99 0.00 0.00]]\n",
      "\n",
      "[9810/ 11000] Loss Dis: 0.61, Loss Gen: 24.40 , 2[s]\n",
      "[9820/ 11000] Loss Dis: 0.53, Loss Gen: 24.58 , 2[s]\n",
      "[9830/ 11000] Loss Dis: 0.54, Loss Gen: 26.52 , 2[s]\n",
      "[9840/ 11000] Loss Dis: 0.58, Loss Gen: 24.86 , 2[s]\n",
      "[9850/ 11000] Loss Dis: 0.55, Loss Gen: 26.34 , 2[s]\n",
      "[9860/ 11000] Loss Dis: 0.60, Loss Gen: 26.96 , 2[s]\n",
      "[9870/ 11000] Loss Dis: 0.92, Loss Gen: 20.30 , 2[s]\n",
      "[9880/ 11000] Loss Dis: 0.75, Loss Gen: 26.82 , 2[s]\n",
      "[9890/ 11000] Loss Dis: 0.73, Loss Gen: 25.25 , 2[s]\n",
      "[9900/ 11000] Loss Dis: 0.61, Loss Gen: 25.50 , 2[s]\n",
      "\n",
      "[[0.00 1.00 0.01 0.00 0.06]\n",
      " [0.05 0.00 0.01 0.00 0.00]\n",
      " [0.01 0.99 0.00 0.00 0.02]\n",
      " [0.02 0.00 1.00 0.00 1.00]\n",
      " [1.00 0.00 0.99 0.00 0.00]]\n",
      "\n",
      "[9910/ 11000] Loss Dis: 0.60, Loss Gen: 24.52 , 2[s]\n",
      "[9920/ 11000] Loss Dis: 0.62, Loss Gen: 27.01 , 2[s]\n",
      "[9930/ 11000] Loss Dis: 0.55, Loss Gen: 26.59 , 2[s]\n",
      "[9940/ 11000] Loss Dis: 0.66, Loss Gen: 26.92 , 2[s]\n",
      "[9950/ 11000] Loss Dis: 0.65, Loss Gen: 25.42 , 2[s]\n",
      "[9960/ 11000] Loss Dis: 0.64, Loss Gen: 28.06 , 2[s]\n",
      "[9970/ 11000] Loss Dis: 0.58, Loss Gen: 26.80 , 2[s]\n",
      "[9980/ 11000] Loss Dis: 0.59, Loss Gen: 26.30 , 2[s]\n",
      "[9990/ 11000] Loss Dis: 0.57, Loss Gen: 27.82 , 2[s]\n",
      "[10000/ 11000] Loss Dis: 0.62, Loss Gen: 32.28 , 2[s]\n",
      "\n",
      "[[0.00 1.00 0.02 0.01 0.06]\n",
      " [0.05 0.00 0.01 0.00 0.00]\n",
      " [0.01 0.99 0.00 0.00 0.02]\n",
      " [0.03 0.00 1.00 0.00 1.00]\n",
      " [1.00 0.00 0.99 0.00 0.00]]\n",
      "\n",
      "[10010/ 11000] Loss Dis: 0.59, Loss Gen: 27.84 , 1[s]\n",
      "[10020/ 11000] Loss Dis: 0.62, Loss Gen: 27.91 , 1[s]\n",
      "[10030/ 11000] Loss Dis: 0.58, Loss Gen: 28.51 , 1[s]\n",
      "[10040/ 11000] Loss Dis: 0.59, Loss Gen: 28.40 , 1[s]\n",
      "[10050/ 11000] Loss Dis: 0.62, Loss Gen: 27.96 , 1[s]\n",
      "[10060/ 11000] Loss Dis: 0.55, Loss Gen: 28.26 , 1[s]\n",
      "[10070/ 11000] Loss Dis: 0.60, Loss Gen: 27.62 , 1[s]\n",
      "[10080/ 11000] Loss Dis: 0.57, Loss Gen: 28.21 , 1[s]\n",
      "[10090/ 11000] Loss Dis: 0.60, Loss Gen: 27.60 , 1[s]\n",
      "[10100/ 11000] Loss Dis: 0.59, Loss Gen: 28.91 , 1[s]\n",
      "\n",
      "[[0.00 1.00 0.02 0.01 0.06]\n",
      " [0.05 0.00 0.01 0.00 0.00]\n",
      " [0.01 0.99 0.00 0.00 0.02]\n",
      " [0.03 0.00 1.00 0.00 1.00]\n",
      " [1.00 0.00 0.99 0.00 0.00]]\n",
      "\n",
      "[10110/ 11000] Loss Dis: 0.57, Loss Gen: 29.33 , 1[s]\n",
      "[10120/ 11000] Loss Dis: 0.57, Loss Gen: 28.15 , 1[s]\n",
      "[10130/ 11000] Loss Dis: 0.57, Loss Gen: 28.26 , 1[s]\n",
      "[10140/ 11000] Loss Dis: 0.59, Loss Gen: 27.83 , 1[s]\n",
      "[10150/ 11000] Loss Dis: 0.58, Loss Gen: 27.60 , 1[s]\n",
      "[10160/ 11000] Loss Dis: 0.58, Loss Gen: 28.00 , 1[s]\n",
      "[10170/ 11000] Loss Dis: 0.57, Loss Gen: 27.94 , 1[s]\n",
      "[10180/ 11000] Loss Dis: 0.58, Loss Gen: 28.04 , 1[s]\n",
      "[10190/ 11000] Loss Dis: 0.57, Loss Gen: 27.75 , 1[s]\n",
      "[10200/ 11000] Loss Dis: 0.38, Loss Gen: 43.22 , 1[s]\n",
      "\n",
      "[[0.00 1.00 0.02 0.01 0.06]\n",
      " [0.05 0.00 0.01 0.00 0.00]\n",
      " [0.01 0.99 0.00 0.00 0.02]\n",
      " [0.03 0.00 1.00 0.00 1.00]\n",
      " [1.00 0.00 0.99 0.00 0.00]]\n",
      "\n",
      "[10210/ 11000] Loss Dis: 0.60, Loss Gen: 27.84 , 1[s]\n",
      "[10220/ 11000] Loss Dis: 0.56, Loss Gen: 28.46 , 1[s]\n",
      "[10230/ 11000] Loss Dis: 0.40, Loss Gen: 40.90 , 1[s]\n",
      "[10240/ 11000] Loss Dis: 0.59, Loss Gen: 28.22 , 1[s]\n",
      "[10250/ 11000] Loss Dis: 0.43, Loss Gen: 40.07 , 1[s]\n",
      "[10260/ 11000] Loss Dis: 0.62, Loss Gen: 26.61 , 1[s]\n",
      "[10270/ 11000] Loss Dis: 0.58, Loss Gen: 28.11 , 1[s]\n",
      "[10280/ 11000] Loss Dis: 0.57, Loss Gen: 28.13 , 1[s]\n",
      "[10290/ 11000] Loss Dis: 0.58, Loss Gen: 27.56 , 1[s]\n",
      "[10300/ 11000] Loss Dis: 0.58, Loss Gen: 27.98 , 1[s]\n",
      "\n",
      "[[0.00 1.00 0.02 0.01 0.06]\n",
      " [0.05 0.00 0.01 0.00 0.00]\n",
      " [0.01 0.99 0.00 0.00 0.02]\n",
      " [0.03 0.00 1.00 0.00 1.00]\n",
      " [1.00 0.00 0.99 0.00 0.00]]\n",
      "\n",
      "[10310/ 11000] Loss Dis: 0.60, Loss Gen: 28.03 , 1[s]\n",
      "[10320/ 11000] Loss Dis: 0.58, Loss Gen: 27.76 , 1[s]\n",
      "[10330/ 11000] Loss Dis: 0.58, Loss Gen: 27.77 , 1[s]\n",
      "[10340/ 11000] Loss Dis: 0.59, Loss Gen: 27.85 , 1[s]\n",
      "[10350/ 11000] Loss Dis: 0.57, Loss Gen: 28.01 , 1[s]\n",
      "[10360/ 11000] Loss Dis: 0.60, Loss Gen: 30.74 , 1[s]\n",
      "[10370/ 11000] Loss Dis: 0.58, Loss Gen: 28.00 , 1[s]\n",
      "[10380/ 11000] Loss Dis: 0.58, Loss Gen: 27.67 , 1[s]\n",
      "[10390/ 11000] Loss Dis: 0.59, Loss Gen: 27.77 , 1[s]\n",
      "[10400/ 11000] Loss Dis: 0.56, Loss Gen: 28.08 , 1[s]\n",
      "\n",
      "[[0.00 1.00 0.02 0.01 0.06]\n",
      " [0.05 0.00 0.01 0.00 0.00]\n",
      " [0.01 0.99 0.00 0.00 0.02]\n",
      " [0.03 0.00 1.00 0.00 1.00]\n",
      " [1.00 0.00 0.99 0.00 0.00]]\n",
      "\n",
      "[10410/ 11000] Loss Dis: 0.59, Loss Gen: 27.88 , 1[s]\n",
      "[10420/ 11000] Loss Dis: 0.59, Loss Gen: 28.14 , 1[s]\n",
      "[10430/ 11000] Loss Dis: 0.58, Loss Gen: 29.04 , 1[s]\n",
      "[10440/ 11000] Loss Dis: 0.57, Loss Gen: 28.52 , 1[s]\n",
      "[10450/ 11000] Loss Dis: 0.60, Loss Gen: 27.99 , 1[s]\n",
      "[10460/ 11000] Loss Dis: 0.57, Loss Gen: 28.50 , 1[s]\n",
      "[10470/ 11000] Loss Dis: 0.36, Loss Gen: 43.49 , 1[s]\n",
      "[10480/ 11000] Loss Dis: 0.59, Loss Gen: 27.69 , 1[s]\n",
      "[10490/ 11000] Loss Dis: 0.60, Loss Gen: 27.98 , 1[s]\n",
      "[10500/ 11000] Loss Dis: 0.57, Loss Gen: 28.08 , 1[s]\n",
      "\n",
      "[[0.00 1.00 0.02 0.01 0.06]\n",
      " [0.05 0.00 0.01 0.00 0.00]\n",
      " [0.01 0.99 0.00 0.00 0.02]\n",
      " [0.03 0.00 1.00 0.00 1.00]\n",
      " [1.00 0.00 0.99 0.00 0.00]]\n",
      "\n",
      "[10510/ 11000] Loss Dis: 0.59, Loss Gen: 27.43 , 1[s]\n",
      "[10520/ 11000] Loss Dis: 0.56, Loss Gen: 28.24 , 1[s]\n",
      "[10530/ 11000] Loss Dis: 0.57, Loss Gen: 27.86 , 1[s]\n",
      "[10540/ 11000] Loss Dis: 0.59, Loss Gen: 34.67 , 1[s]\n",
      "[10550/ 11000] Loss Dis: 0.58, Loss Gen: 28.00 , 1[s]\n",
      "[10560/ 11000] Loss Dis: 0.86, Loss Gen: 20.33 , 1[s]\n",
      "[10570/ 11000] Loss Dis: 0.58, Loss Gen: 28.18 , 1[s]\n",
      "[10580/ 11000] Loss Dis: 0.60, Loss Gen: 27.78 , 1[s]\n",
      "[10590/ 11000] Loss Dis: 0.57, Loss Gen: 28.04 , 1[s]\n",
      "[10600/ 11000] Loss Dis: 0.64, Loss Gen: 30.41 , 1[s]\n",
      "\n",
      "[[0.00 1.00 0.02 0.01 0.06]\n",
      " [0.05 0.00 0.01 0.00 0.00]\n",
      " [0.01 0.99 0.00 0.00 0.02]\n",
      " [0.03 0.00 1.00 0.00 1.00]\n",
      " [1.00 0.00 0.99 0.00 0.00]]\n",
      "\n",
      "[10610/ 11000] Loss Dis: 0.59, Loss Gen: 27.82 , 1[s]\n",
      "[10620/ 11000] Loss Dis: 0.61, Loss Gen: 27.29 , 1[s]\n",
      "[10630/ 11000] Loss Dis: 0.56, Loss Gen: 28.07 , 1[s]\n",
      "[10640/ 11000] Loss Dis: 0.60, Loss Gen: 28.14 , 1[s]\n",
      "[10650/ 11000] Loss Dis: 0.57, Loss Gen: 28.33 , 1[s]\n",
      "[10660/ 11000] Loss Dis: 0.59, Loss Gen: 28.65 , 1[s]\n",
      "[10670/ 11000] Loss Dis: 0.58, Loss Gen: 27.73 , 1[s]\n",
      "[10680/ 11000] Loss Dis: 0.81, Loss Gen: 20.86 , 1[s]\n",
      "[10690/ 11000] Loss Dis: 0.59, Loss Gen: 27.80 , 1[s]\n",
      "[10700/ 11000] Loss Dis: 0.62, Loss Gen: 27.91 , 1[s]\n",
      "\n",
      "[[0.00 1.00 0.02 0.01 0.06]\n",
      " [0.05 0.00 0.01 0.00 0.00]\n",
      " [0.01 0.99 0.00 0.00 0.02]\n",
      " [0.03 0.00 1.00 0.00 1.00]\n",
      " [1.00 0.00 0.99 0.00 0.00]]\n",
      "\n",
      "[10710/ 11000] Loss Dis: 0.59, Loss Gen: 28.00 , 1[s]\n",
      "[10720/ 11000] Loss Dis: 0.56, Loss Gen: 28.02 , 1[s]\n",
      "[10730/ 11000] Loss Dis: 0.58, Loss Gen: 27.89 , 1[s]\n",
      "[10740/ 11000] Loss Dis: 0.59, Loss Gen: 27.84 , 1[s]\n",
      "[10750/ 11000] Loss Dis: 0.60, Loss Gen: 29.26 , 1[s]\n",
      "[10760/ 11000] Loss Dis: 0.58, Loss Gen: 28.03 , 1[s]\n",
      "[10770/ 11000] Loss Dis: 0.37, Loss Gen: 43.36 , 1[s]\n",
      "[10780/ 11000] Loss Dis: 0.57, Loss Gen: 27.40 , 1[s]\n",
      "[10790/ 11000] Loss Dis: 0.57, Loss Gen: 28.23 , 1[s]\n",
      "[10800/ 11000] Loss Dis: 0.58, Loss Gen: 27.97 , 1[s]\n",
      "\n",
      "[[0.00 1.00 0.02 0.01 0.06]\n",
      " [0.05 0.00 0.01 0.00 0.00]\n",
      " [0.01 0.99 0.00 0.00 0.02]\n",
      " [0.03 0.00 1.00 0.00 1.00]\n",
      " [1.00 0.00 0.99 0.00 0.00]]\n",
      "\n",
      "[10810/ 11000] Loss Dis: 0.59, Loss Gen: 28.51 , 1[s]\n",
      "[10820/ 11000] Loss Dis: 0.51, Loss Gen: 45.65 , 1[s]\n",
      "[10830/ 11000] Loss Dis: 0.57, Loss Gen: 28.13 , 1[s]\n",
      "[10840/ 11000] Loss Dis: 0.57, Loss Gen: 28.02 , 1[s]\n",
      "[10850/ 11000] Loss Dis: 0.56, Loss Gen: 34.74 , 1[s]\n",
      "[10860/ 11000] Loss Dis: 0.61, Loss Gen: 27.08 , 1[s]\n",
      "[10870/ 11000] Loss Dis: 0.55, Loss Gen: 35.38 , 1[s]\n",
      "[10880/ 11000] Loss Dis: 0.59, Loss Gen: 33.86 , 1[s]\n",
      "[10890/ 11000] Loss Dis: 0.57, Loss Gen: 27.00 , 1[s]\n",
      "[10900/ 11000] Loss Dis: 0.57, Loss Gen: 27.83 , 1[s]\n",
      "\n",
      "[[0.00 1.00 0.02 0.01 0.06]\n",
      " [0.05 0.00 0.01 0.00 0.00]\n",
      " [0.01 0.99 0.00 0.00 0.02]\n",
      " [0.03 0.00 1.00 0.00 1.00]\n",
      " [1.00 0.00 0.99 0.00 0.00]]\n",
      "\n",
      "[10910/ 11000] Loss Dis: 0.57, Loss Gen: 27.77 , 1[s]\n",
      "[10920/ 11000] Loss Dis: 0.57, Loss Gen: 28.27 , 1[s]\n",
      "[10930/ 11000] Loss Dis: 0.58, Loss Gen: 28.28 , 1[s]\n",
      "[10940/ 11000] Loss Dis: 0.36, Loss Gen: 43.27 , 1[s]\n",
      "[10950/ 11000] Loss Dis: 0.57, Loss Gen: 28.73 , 1[s]\n",
      "[10960/ 11000] Loss Dis: 0.60, Loss Gen: 27.73 , 1[s]\n",
      "[10970/ 11000] Loss Dis: 0.58, Loss Gen: 27.94 , 1[s]\n",
      "[10980/ 11000] Loss Dis: 0.59, Loss Gen: 27.21 , 1[s]\n",
      "[10990/ 11000] Loss Dis: 0.58, Loss Gen: 27.86 , 1[s]\n",
      "[11000/ 11000] Loss Dis: 0.39, Loss Gen: 41.08 , 1[s]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(epochs_train + epochs_test):\n",
    "    for loop_num, data_batched in enumerate(data_iterator):\n",
    "\n",
    "        optimizer_gen.zero_grad()\n",
    "        optimizer_graph.zero_grad()\n",
    "        optimizer_neuron.zero_grad()\n",
    "        optimizer_dis.zero_grad()\n",
    "\n",
    "        drawn_graph = sampler_graph()\n",
    "        drawn_neurons = sampler_neuron()\n",
    "\n",
    "        noise.normal_()\n",
    "        generated_variables = sam(\n",
    "            data=data_batched, \n",
    "            noise=noise,\n",
    "            adj_matrix=torch.cat(\n",
    "                [drawn_graph, noise_row], 0\n",
    "            ), \n",
    "            drawn_neurons=drawn_neurons\n",
    "        )\n",
    "\n",
    "        dis_vars_d = discriminator(generated_variables.detach(), data_batched)\n",
    "        true_vars_dis = discriminator(data_batched) \n",
    "\n",
    "        loss_dis = sum(\n",
    "            [criterion(gen, _false.expand_as(gen)) for gen in dis_vars_d]\n",
    "        ) / n_data_col + criterion(\n",
    "            true_vars_dis, _true.expand_as(true_vars_dis)\n",
    "        )\n",
    "        \n",
    "        if epoch < epochs_train:\n",
    "            loss_dis.backward()\n",
    "            optimizer_dis.step()\n",
    "\n",
    "        loss_struc = lambda1 / batch_size * drawn_graph.sum()     \n",
    "        loss_func = lambda2 / batch_size * drawn_neurons.sum()  \n",
    "\n",
    "        loss_regul = loss_struc + loss_func\n",
    "        \n",
    "        dis_vars_g = discriminator(generated_variables, data_batched)\n",
    "        loss_gen = sum([criterion(gen, _true.expand_as(gen)) for gen in dis_vars_g])\n",
    "\n",
    "        if epoch <= epochs_train * dag_start_rate:\n",
    "            loss = loss_gen + loss_regul\n",
    "        else:\n",
    "            filters = sampler_graph.get_proba()\n",
    "            loss = loss_gen + loss_regul + (\n",
    "                (epoch - epochs_train * dag_start_rate) * dag_penalization_increase\n",
    "            ) * notears_constr(filters * filters)\n",
    "\n",
    "        if epoch >= epochs_train:\n",
    "            output.add_(filters.data)\n",
    "            output_loss.add_(loss_gen.data)\n",
    "        else:\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer_gen.step()\n",
    "            optimizer_graph.step()\n",
    "            optimizer_neuron.step()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            \n",
    "            print('[{}/ {}] Loss Dis: {:.2f}, Loss Gen: {:.2f} , {:.0f}[s]'.format(\n",
    "                epoch + 1, epochs_train + epochs_test, loss_dis, loss_gen, time.time() - start_time\n",
    "            ))\n",
    "            start_time = time.time()\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print('')\n",
    "            print(sampler_graph.get_proba().detach().numpy())\n",
    "            print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [08:38<00:00,  3.86it/s, dis=0.681, egul_loss=0.559, gen=3.26, tot=32.5]\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.95]]\n",
      "[[0.00 0.20 0.15 0.03 0.05 0.04]\n",
      " [0.91 0.00 0.53 0.42 0.11 0.47]\n",
      " [0.41 0.62 0.00 0.83 0.30 0.58]\n",
      " [0.05 0.02 0.02 0.00 0.06 0.02]\n",
      " [0.14 0.05 0.25 0.94 0.00 0.52]\n",
      " [0.07 0.05 0.19 0.39 0.90 0.00]]\n",
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [10:14<00:00,  3.25it/s, dis=1.11, egul_loss=0.561, gen=5.09, tot=46.6] \n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.40]]\n",
      "[[0.00 0.05 0.63 0.05 0.04 0.05]\n",
      " [0.89 0.00 0.65 0.52 0.17 0.56]\n",
      " [0.04 0.49 0.00 0.32 0.25 0.77]\n",
      " [0.04 0.03 0.03 0.00 0.07 0.07]\n",
      " [0.64 0.01 0.07 0.89 0.00 0.63]\n",
      " [0.40 0.07 0.04 0.83 0.84 0.00]]\n",
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [08:44<00:00,  3.81it/s, dis=0.896, egul_loss=0.408, gen=2.58, tot=21.9]\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.98]]\n",
      "[[0.00 0.20 0.42 0.04 0.03 0.08]\n",
      " [0.54 0.00 0.22 0.49 0.12 0.17]\n",
      " [0.15 0.85 0.00 0.85 0.73 0.18]\n",
      " [0.07 0.02 0.02 0.00 0.17 0.02]\n",
      " [0.23 0.03 0.05 0.89 0.00 0.90]\n",
      " [0.14 0.07 0.07 0.45 0.33 0.00]]\n",
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [10:02<00:00,  3.32it/s, dis=0.907, egul_loss=0.56, gen=1.84, tot=26.5] \n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.64]]\n",
      "[[0.00 0.85 0.63 0.18 0.05 0.05]\n",
      " [0.09 0.00 0.39 0.58 0.09 0.02]\n",
      " [0.08 0.93 0.00 0.81 0.48 0.16]\n",
      " [0.03 0.02 0.04 0.00 0.13 0.03]\n",
      " [0.11 0.03 0.21 0.87 0.00 0.82]\n",
      " [0.12 0.04 0.17 0.72 0.69 0.00]]\n",
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [09:51<00:00,  3.38it/s, dis=0.512, egul_loss=0.458, gen=4.67, tot=41.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.17]]\n",
      "[[0.00 0.25 0.12 0.18 0.03 0.05]\n",
      " [0.89 0.00 0.51 0.10 0.12 0.07]\n",
      " [0.29 0.93 0.00 0.86 0.56 0.03]\n",
      " [0.04 0.03 0.05 0.00 0.10 0.03]\n",
      " [0.38 0.02 0.14 0.88 0.00 0.90]\n",
      " [0.22 0.16 0.11 0.59 0.40 0.00]]\n",
      "[[0.00 0.31 0.39 0.09 0.04 0.06]\n",
      " [0.66 0.00 0.46 0.42 0.12 0.26]\n",
      " [0.19 0.76 0.00 0.73 0.47 0.35]\n",
      " [0.05 0.02 0.03 0.00 0.11 0.03]\n",
      " [0.30 0.03 0.14 0.89 0.00 0.75]\n",
      " [0.19 0.08 0.12 0.59 0.63 0.00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "m_list = []\n",
    "loss_list = []\n",
    "\n",
    "for i in range(5):\n",
    "    m, loss = train_sam_model(\n",
    "        data=learning_data.copy(),\n",
    "        n_hidden_layer_gen=100, n_hidden_layer_dis=100,\n",
    "        n_hidden_layers_dis=2,\n",
    "        lr_gen=0.01*0.5, lr_dis=0.01*0.5*2,\n",
    "        dag_start_rate=0.5,\n",
    "        dag_penalization_increase=0.001*10,\n",
    "        epochs_train=1000, epochs_test=1000,\n",
    "        lambda1=5.0 * 20, lambda2=0.005 * 20\n",
    "    )\n",
    "\n",
    "    print(loss)\n",
    "    print(m)\n",
    "\n",
    "    m_list.append(m)\n",
    "    loss_list.append(loss)\n",
    "\n",
    "# ネットワーク構造（5回の平均）\n",
    "print(sum(m_list) / len(m_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=learning_data.copy()\n",
    "n_hidden_layer_gen=200\n",
    "n_hidden_layer_dis=200\n",
    "n_hidden_layers_dis=2\n",
    "lr_gen=0.01*0.5\n",
    "lr_dis=0.01*0.5*2\n",
    "dag_start_rate=0.5\n",
    "dag_penalization_increase=0.001*10\n",
    "epochs_train=10000\n",
    "epochs_test=1000\n",
    "lambda1=5.0*20\n",
    "lambda2=0.005*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_columns = data.columns.tolist() \n",
    "n_data_col = len(data_columns)  \n",
    "data = torch.from_numpy(data.values.astype('float32') )\n",
    "batch_size = len(data)\n",
    "\n",
    "data_iterator = DataLoader(\n",
    "    data, batch_size=batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "\n",
    "sam = SAMGenerator(n_data_col, n_hidden_layer_gen)\n",
    "sam.reset_parameters()\n",
    "sampler_graph = MatrixSampler(n_data_col, mask=None, gumbel=False)\n",
    "sampler_neuron = MatrixSampler((n_hidden_layer_gen, n_data_col), mask=False, gumbel=True)\n",
    "\n",
    "sampler_graph.weights.data.fill_(2)\n",
    "\n",
    "discriminator = SAMDiscriminator(\n",
    "    n_data_col=n_data_col, n_hidden_layer=n_hidden_layer_dis, n_hidden_layers=n_hidden_layers_dis\n",
    ")\n",
    "discriminator.reset_parameters()  \n",
    "\n",
    "optimizer_gen = optim.Adam(sam.parameters(), lr=lr_gen)\n",
    "optimizer_dis = optim.Adam(discriminator.parameters(), lr=lr_dis)\n",
    "optimizer_graph = optim.Adam(sampler_graph.parameters(), lr=lr_gen)\n",
    "optimizer_neuron = optim.Adam(sampler_neuron.parameters(), lr=lr_gen)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "_true = torch.ones(1)\n",
    "_false = torch.zeros(1)\n",
    "\n",
    "noise = torch.randn(batch_size, n_data_col)\n",
    "noise_row = torch.ones(1, n_data_col)\n",
    "\n",
    "output = torch.zeros(n_data_col, n_data_col)\n",
    "output_loss = torch.zeros(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 133/11000 [01:34<2:08:22,  1.41it/s, dis=1.39, egul_loss=1.42, gen=0.694, tot=5.59]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-caa8dc614307>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0moutput_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0moptimizer_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0moptimizer_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pbar = tqdm(range(epochs_train + epochs_test))\n",
    "for epoch in pbar:\n",
    "    for loop_num, data_batched in enumerate(data_iterator):\n",
    "\n",
    "        optimizer_gen.zero_grad()\n",
    "        optimizer_graph.zero_grad()\n",
    "        optimizer_neuron.zero_grad()\n",
    "        optimizer_dis.zero_grad()\n",
    "\n",
    "        drawn_graph = sampler_graph()\n",
    "        drawn_neurons = sampler_neuron()\n",
    "\n",
    "        noise.normal_()\n",
    "        generated_variables = sam(\n",
    "            data=data_batched, \n",
    "            noise=noise,\n",
    "            adj_matrix=torch.cat(\n",
    "                [drawn_graph, noise_row], 0\n",
    "            ), drawn_neurons=drawn_neurons\n",
    "        )\n",
    "\n",
    "        dis_vars_d = discriminator(generated_variables.detach(), data_batched)\n",
    "        dis_vars_g = discriminator(generated_variables, data_batched)\n",
    "        true_vars_dis = discriminator(data_batched) \n",
    "\n",
    "        loss_dis = sum(\n",
    "            [criterion(gen, _false.expand_as(gen)) for gen in dis_vars_d]\n",
    "        ) / n_data_col + criterion(\n",
    "            true_vars_dis, _true.expand_as(true_vars_dis)\n",
    "        )\n",
    "\n",
    "        loss_gen = sum([criterion(gen, _true.expand_as(gen)) for gen in dis_vars_g])\n",
    "\n",
    "        if epoch < epochs_train:\n",
    "            loss_dis.backward()\n",
    "            optimizer_dis.step()\n",
    "\n",
    "        loss_struc = lambda1 / batch_size * drawn_graph.sum()     \n",
    "        loss_func = lambda2 / batch_size * drawn_neurons.sum()  \n",
    "\n",
    "        loss_regul = loss_struc + loss_func\n",
    "\n",
    "        if epoch <= epochs_train * dag_start_rate:\n",
    "            loss = loss_gen + loss_regul\n",
    "        else:\n",
    "            filters = sampler_graph.get_proba()\n",
    "            loss = loss_gen + loss_regul + (\n",
    "                (epoch - epochs_train * dag_start_rate) * dag_penalization_increase\n",
    "            ) * notears_constr(filters * filters)\n",
    "\n",
    "        if epoch >= epochs_train:\n",
    "            output.add_(filters.data)\n",
    "            output_loss.add_(loss_gen.data)\n",
    "        else:\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer_gen.step()\n",
    "            optimizer_graph.step()\n",
    "            optimizer_neuron.step()\n",
    "\n",
    "        # 進捗の表示\n",
    "        if epoch % 50 == 0:\n",
    "            pbar.set_postfix(\n",
    "                gen=loss_gen.item()/n_data_col,\n",
    "                dis=loss_dis.item(),\n",
    "                egul_loss=loss_regul.item(),\n",
    "                tot=loss.item()\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in pbar:\n",
    "    for i_batch, data_batched in enumerate(data_iterator):\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
